---
title: "Simulation Results"
output: pdf_document
bibliography: references.bib
---

```{r sim-results-setup}
source("process-simulation-results.R")

CML_bias <- 
  mu_graph_res %>%
  filter(estimator == "CML") %>%
  summarize(
    max_abs_bias = max(abs(bias))
  )

convergence_min <- 
  mu_graph_res %>%
  filter(model == "3PSM") %>%
  group_by(estimator) %>%
  filter(
    convergence == min(convergence)
  )

```

We organize our presentation of simulation study results by first considering the properties of point and interval estimators for the average effect size. 
For this parameter, we compare the bias and accuracy of the CML and ARGL estimators to that of the CHE-ISCW estimator and the PET/PEESE estimator.
We also examine the calibration of cluster-robust and bootstrap confidence intervals based on the CML and ARGL estimators. 
We then briefly consider the bias and accuracy of estimators  of the marginal variance of the effect size distribution and the selection parameter in the step-function model. 

## Average Effect Size

The CHE-ISCW and PET/PEESE estimators produced results for every replication in every condition. 
The CML and ARGL estimators for the step-function selection model had very high convergence rates across most conditions, although the CML estimator did exhibit rates of convergence below 99% under conditions with the lowest degree of heterogeneity $\tau = 0.05$, with the lowest convergence rate of `r round(100 * convergence_min %>% filter(estimator == "CML") %>% pull(convergence), 1)`%.
For the ARGL estimator, convergence was above `r round(100 * convergence_min %>% filter(estimator == "ARGL") %>% pull(convergence), 1)`% across all conditions.
Supplementary Figure \@ref(fig:convergence-rates) depicts the range of convergence rates of the CML and ARGL estimators.
We evaluated the performance characteristics of these estimators across replications where they converged.

### Bias

```{r mu-bias}
#| fig.width: 9
#| fig.height: 6.5
#| fig.env: "sidewaysfigure"
#| fig.cap: "Bias for estimators of average effect size by selection probability, average SMD, and between-study heterogeneity"

ggplot(mu_graph_res) + 
  aes(x = weights, y = bias, color = estimator, fill = estimator) +
  geom_hline(yintercept = 0) +
  geom_boxplot(alpha = .5, coef = Inf) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 3))+
  facet_grid(
    tau ~ mean_smd, 
    labeller = label_bquote(
      rows = tau == .(tau),
      cols = mu == .(mean_smd)
    ),
    scales = "free_y"
  ) +
  labs(
    x = "Selection probability", 
    y = "Bias", 
    color = "Estimator",
    fill = "Estimator"
  ) + 
  theme_bw() +
  theme(legend.position = "top")

```

Figure \@ref(fig:mu-bias) depicts the bias (represented on the vertical axis of each plot) of each estimator of average effect size as a function of the strength of selective reporting (horizontal axis), average effect size parameter (varying by grid column), and  between-study heterogeneity ($\tau$, varying by grid row).
The box plot for each estimator depicts variation in bias over the remaining factors in the simulation design, which include the heterogeneity ratio, correlation between effect size estimates, number of observed studies, and primary study sample size distribution.
Note that the range of the vertical axis differs by grid row because the bias of some estimators is strongly influenced by the degree of heterogeneity.

The CML estimator has negligible or small bias across all conditions. 
Its largest bias was `r round(CML_bias$max_abs_bias,2)`, occurring when selective reporting is very strong, average effect size is zero, and heterogeneity is large.
The small bias of the CML estimator is stable across varying degrees of outcome correlation, within-study heterogeneity, number of observed studies, and primary study sample size.
Similar to the CML estimator, the ARGL estimator also has negligible or small bias across most conditions, although its bias increases when average effect is zero and selection is very strong.

In contrast to the estimators based on the marginal selection model, the comparison estimators are systematically biased under many conditions. 
The CHE-ISCW estimator, which does not directly adjust for selective reporting, is systematically biased under conditions with non-null selection.
When average effect size is large $(\mu = 0.8)$, its bias remains quite small even when selective reporting is very strong.
However, the bias of CHE-ISCW grows stronger when selection is more extreme, when average effect size is smaller, and when heterogeneity is larger; its bias exceeds 0.50 when $\mu = 0.0$, $\tau = 0.45$, and $\lambda_1 = 0.02$.
Although the PET/PEESE estimator uses a regression adjustment to account for possible selective reporting, it too becomes severely biased when selective reporting is strong.
For smaller values of average effect size $(\mu \leq 0.2)$, the bias of PET/PEESE tracks the bias of the CHE-ISCW estimator but is somewhat less pronounced. Its bias grows larger (and closer to that of CHE-ISCW) for smaller values of average effect size and higher levels of heterogeneity.
For larger values of average effect size $(\mu = 0.8)$, the PET/PEESE estimator is negatively biased, systematically under-estimating the average effect size---especially at high levels of heterogeneity.

### Scaled RMSE

```{r mu-rmse}
#| fig.width: 9
#| fig.height: 6.5
#| fig.env: "sidewaysfigure"
#| fig.cap: "Scaled root mean-squared error for estimators of average effect size by selection probability, average SMD, and between-study heterogeneity"

ggplot(mu_graph_res) + 
  aes(x = weights, y = scrmse, color = estimator, fill = estimator) +
  geom_hline(yintercept = 0) +
  geom_boxplot(alpha = .5, coef = Inf) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 3))+
  facet_grid(
    tau ~ mean_smd, 
    labeller = label_bquote(
      rows = tau == .(tau),
      cols = mu == .(mean_smd)
    ),
    scales = "free_y"
  ) +
  labs(
    x = "Selection probability", 
    y = "Scaled Root Mean-Squared Error", 
    color = "Estimator",
    fill = "Estimator"
  ) + 
  theme_bw() +
  theme(legend.position = "top")
```

Scaled RMSE combines both bias and variability into an overall measure of inaccuracy. 
Figure \@ref(fig:mu-rmse) depicts the scaled RMSE of each estimator of average effect size; it is constructed in the same way as Figure \@ref(fig:mu-bias). 
Figures \@ref(fig:rmse-ARGL-CML) through \@ref(fig:rmse-PET-ARGL) in Appendix \@ref(mu-simulation-results) provide greater detail about the relative accuracy of the four methods by plotting the ratio of RMSEs for each pair of methods. 
These figures illustrate several findings.

First, across most data-generating conditions, the ARGL estimator has higher RMSE than the CML estimator. As evident in Figure \@ref(fig:rmse-ARGL-CML), the RMSE ratio comparing ARGL to CML is greater than one across most conditions examined.
The ARGL estimator has lower RMSE only under conditions of very high heterogeneity and in databases with few studies.
Thus, the CML will typically be preferable to the ARGL estimator.

Second, considering both the selection model estimators and comparison methods, no single method achieves the lowest RMSE uniformly across all conditions examined. 
Instead, all methods face bias-variance trade-offs. 
Under conditions with small or moderate average effect size and moderate or strong selection, the selection model estimators generally have lower RMSE than the CHE-ISCW and PET/PEESE estimators.
The CML estimator has lower RMSE than CHE-ISCW under most conditions where selective reporting creates meaningful bias---specifically, for $\lambda_1 <= 0.2$ and $\mu \leq 0.2$ (Figure \@ref(fig:rmse-CHE-CML)).
The relative accuracy of the ARGL estimator versus CHE-ISCW follows a similar pattern  (Figure \@ref(fig:rmse-CHE-ARGL)).

Third, the CML estimator also has lower RMSE than PET/PEESE under conditions where selective reporting creates meaningful bias, although it is not uniformly more accurate than PET/PEESE (Figure \@ref(fig:rmse-PET-CML)). 
Rather, PET/PEESE is more accurate under _some_ conditions involving moderate or large effect size $(\mu \geq 0.4)$ and varying degrees of between-study heterogeneity, 
which correspond to conditions where the bias of PET/PEESE is small.
The relative accuracy is difficult to characterize generally because it follows a non-linear pattern involving interactions among the data-generating parameters. 
The pattern of relative accuracy is very similar for the ARGL estimator (Figure \@ref(fig:rmse-PET-ARGL)).

The bias-variance trade-offs faced by all the estimators arise because the CHE-ISCW estimator (which does not directly adjust for selection) is substantially biased by selective reporting, whereas the CML and ARGL estimators have at most small biases. 
However, under conditions where selection is absent or small and where average effect size is larger, the CHE-ISCW estimator has greater precision than the estimators that adjust for selective reporting.
Because selective reporting does not create much bias under such conditions, the additional variability that comes with estimating a selection model or PET/PEESE adjustment dominates the small reduction in bias that these methods provide. 

### Confidence Interval Coverage

Figure \@ref(fig:comparison-coverage) shows the coverage rates of 95% CIs based on large-sample cluster-robust variance estimators for the CHE-ISCW, PET/PEESE, CML, and ARGL estimators.^[To provide greater detail, the vertical axis of Figure \@ref(fig:comparison-coverage) is limited to the range [0.5, 1.0], and coverage rates of the CHE-ISCW and PET/PEESE intervals are not depicted when they fall below 0.5. Supplementary Figure \@ref(fig:comparison-coverage-full) depicts the full range of coverage rates.]
Coverage rates are below the nominal rate of 0.95 for all methods across most conditions. 
The CML and ARGL estimators based on the step-function selection model have higher coverage rates than the comparison methods under many conditions, particularly in conditions with higher between-study heterogeneity,  
Intervals based on the CML and ARGL estimators have coverage levels that improve towards 0.95 as the number of studies increases, but are often still unacceptably low even when $J \geq 90$ or greater.
In contrast, intervals based on CHE-ISCW and PET/PEESE are often wildly mis-calibrated because of the biases of the point estimators around which the intervals are centered.
Under conditions where CHE-ISCW and PET/PEESE are biased by selective reporting, their confidence intervals do not center on the true parameter. Consequently, as the number of studies increases, the standard error of the estimators decreases (as does the width of confidence intervals) and their coverage rates degrade towards zero.

```{r comparison-coverage}
#| fig.width: 9
#| fig.height: 6.5
#| fig.env: "sidewaysfigure"
#| fig.cap: "Coverage levels of confidence intervals based for average effect size based on cluster-robust variance approximations, by number of studies, average SMD, and between-study heterogeneity. Dashed lines correspond to the nominal confidence level of 0.95. Coverage rates of the CHE-ISCW and PET/PEESE intervals are not depicted when they fall below 0.5"

mu_graph_res_ci %>%
  filter(
    CI_type %in% c("large-sample")
  ) %>%
  ggplot(aes(x = J, y = coverage, color = estimator, fill = estimator)) +
  geom_boxplot(alpha = .5, coef = Inf) +
  geom_hline(yintercept = 0.95, linetype = "dashed") +
  coord_cartesian(ylim = c(0.5, 1.0)) + 
  scale_y_continuous(expand = expansion(c(0,0),c(0.02,0))) + 
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  facet_grid(
    tau ~ mean_smd, 
    labeller = label_bquote(
      rows = tau == .(tau),
      cols = mu == .(mean_smd)
    ),
    scales = "free_y"
  ) +
  labs(
    x = "Number of studies (J)", 
    y = "Coverage rate", 
    color = "Estimator",
    fill = "Estimator"
  ) + 
  theme_bw() +
  theme(legend.position = "top")

```

Bootstrap intervals for the step-function model provide more accurate coverage levels.
Due to the computational demands of bootstrapping, we evaluated the bootstrap confidence intervals under a more limited range of data-generating conditions, including a maximum sample size of $J = 60$. 
Figure \@ref(fig:CML-coverage) depicts the coverage levels of confidence intervals based on the CML estimator, including intervals based on large-sample cluster-robust variance methods and percentile intervals using either two-stage, multinomial (non-parametric), or exponential (fractional reweighted) bootstrap resampling.
Although none of the intervals provide exactly nominal coverage, all versions of the percentile bootstrap intervals have coverage that is closer to nominal than the intervals based on cluster-robust variance estimation. 
In particular, the percentile intervals with two-stage clustered bootstrap re-sampling provided the best coverage levels, exceeding 90% coverage across nearly all data-generating conditions, even with only $J = 15$ primary studies per meta-analysis. 
Coverage levels of the other bootstrap intervals, including studentized, basic, and BCa intervals, were not as accurate as percentile intervals (see Supplementary Figures \@ref(fig:CML-coverage-two-stage)-\@ref(fig:CML-coverage-exponential) for detailed results).
Coverage levels of intervals based on the ARGL estimator followed very similar patterns to those for the CML estimator (Supplementary Figures \@ref(fig:ARGL-coverage-two-stage)-\@ref(fig:ARGL-coverage-exponential)).

```{r CML-coverage}
#| fig.width: 9
#| fig.height: 5
#| fig.env: "sidewaysfigure"
#| fig.cap: "Coverage levels of confidence intervals based on the CML estimator of average effect size by number of studies, average SMD, and between-study heterogeneity. Dashed lines correspond to the nominal confidence level of 0.95."

mu_graph_res_ci %>%
  filter(
    bootstrap_condition == "bootstrap",
    estimator %in% c("CML"),
    CI_type %in% c("large-sample","percentile")
  ) %>%
  ggplot(aes(x = J, y = coverage, color = CI_boot_method, fill = CI_boot_method)) +
  geom_boxplot(alpha = .5, coef = Inf) +
  geom_hline(yintercept = 0.95, linetype = "dashed") +
  scale_y_continuous(limits = c(0.75, 1.0), breaks = seq(0.75,0.95,0.05), expand = expansion(0,0)) +
  scale_color_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  facet_grid(
    tau ~ mean_smd,
    labeller = label_bquote(
      rows = tau == .(tau),
      cols = mu == .(mean_smd)
    ),
    scales = "free_y"
  ) +
  labs(
    x = "Number of studies (J)",
    y = "Coverage rate",
    color = "Method",
    fill = "Method"
  ) +
  theme_bw() +
  theme(legend.position = "top")

```


## Effect Size Variance

We briefly consider estimation of the marginal heterogeneity of the effect size distribution, for which the CHE, CML, and ARGL methods are all relevant.^[We omitted the variance estimator from the CHE-ISCW method because it is identical to that of CHE.]
Figure \@ref(fig:heterogeneity-bias) depicts the bias for the CHE, CML, and ARGL estimators of log-heterogeneity $\gamma = \log(\tau^2)$. 
In most conditions, the estimators are biased in the negative direction. Bias is high for all three estimators in conditions where the between-study heterogeneity is low ($\tau = 0.05$) with bias improving as between-study heterogeneity increases. The CML estimator is less strongly biased than the CHE estimator under conditions where there is strong selection. 
However, the ARGL estimator is badly biased downward, especially under conditions where selection is strong, average SMD is low and between-study heterogeneity is low. 

Figure \@ref(fig:heterogeneity-rmse) depicts the scaled RMSE for estimators of log-heterogeneity, with Figures \@ref(fig:heterogeneity-rmse-ARGL-CHE) and \@ref(fig:heterogeneity-rmse-ARGL-CML) providing greater detail about the relative accuracy of the three methods. 
Under nearly all conditions, the CML estimator is much more accurate than the ARGL estimator. 
The RMSE of CML is smaller than that of CHE under some but not all conditions; the former performs better under conditions where selection is strong, average SMD is low, between-study heterogeneity is large, and sample size is large.
However, just as with the estimators of average effect size, the CHE estimator is more accurate when selection is mild or absent, leading to a bias-variance trade-off.

## Selection Parameter

The CML and ARGL methods both estimate the log-selection parameter of the step-function model, a parameter that may be of substantive interest. 
Figure \@ref(fig:selection-bias) shows that the bias of the two estimators is similar: Both show bias close to zero under conditions with low average SMD and high between-study heterogeneity but have large negative biases under conditions with strong selection probability and high average SMD, especially with low between-study heterogeneity. 
Figure \@ref(fig:selection-rmse) depicts the RMSE for the ARGL and CML estimators of the log-selection parameter with Figure \@ref(fig:selection-rmse-ARGL-CML) providing a more detailed view of the relative accuracy of the ARGL versus the CML estimators. 
The CML estimator of the selection parameter generally outperforms the ARGL estimator, especially under conditions with strong selection. 
Figures \@ref(fig:CML-zeta-coverage-two-stage) and \@ref(fig:ARGL-zeta-coverage-two-stage) depict the confidence interval coverage of the two estimators with various bootstrap confidence interval estimation approaches, using two-stage clustered bootstrap resampling.
Broadly, none of the methods provide coverage rates that are close to the nominal 95% level across all conditions examined.
