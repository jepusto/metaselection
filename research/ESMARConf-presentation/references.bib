  @Manual{metaselection,
    title = {metaselection: Meta-analytic selection models with cluster-robust and
cluster-bootstrap standard errors for dependent effect size
estimates},
    author = {James Pustejovsky and Megha Joshi},
    year = {2025},
    note = {R package version 0.1.2},
    url = {https://github.com/jepusto/metaselection},
  }

@article{arellano20006unification,
	title = {On the Unification of Families of Skew-normal Distributions},
	volume = {33},
	doi = {10.1111/j.1467-9469.2006.00503.x},
	number = {3},
	journal = {Scandinavian Journal of Statistics},
	author = {Arellano-Valle, Reinaldo B. and Azzalini, Adelchi},
	year = {2006},
	pages = {561--574},
}

@article{arnold1999nontruncated,
	title = {The nontruncated marginal of a truncated bivariate normal distribution},
	volume = {58},
	doi = {10.1007/BF02294652},
	number = {3},
	journal = {Psychometrika},
	author = {Arnold, Barry C. and Beaver, Robert J. and Groeneveld, Richard A. and Meeker, William Q.},
	year = {1993},
	pages = {471--488},
}

@article{augusteijn2019effect,
  title = {The Effect of Publication Bias on the {{Q}} Test and Assessment of Heterogeneity},
  author = {Augusteijn, Hilde E. M. and family=Aert, given=Robbie C. M., prefix=van, useprefix=true and family=Assen, given=Marcel A. L. M., prefix=van, useprefix=true},
  date = {2019},
  journaltitle = {Psychological Methods},
  volume = {24},
  number = {1},
  pages = {116--134},
  doi = {10.1037/met0000197},
}


@misc{bai2021robust,
	title = {A Robust {Bayesian} {Copas} selection model for quantifying and correcting publication bias},
	url = {http://arxiv.org/abs/2005.02930},
	doi = {10.48550/arXiv.2005.02930},
	publisher = {arXiv},
	author = {Bai, Ray and Lin, Lifeng and Boland, Mary R. and Chen, Yong},
	year = {2021},
}

@article{baskerville2012,
	title = {Systematic review and meta-analysis of practice facilitation within primary care settings},
	volume = {10},
	issn = {1544-1717},
	doi = {10.1370/afm.1312},
	language = {eng},
	number = {1},
	journal = {Annals of Family Medicine},
	author = {Baskerville, N. Bruce and Liddy, Clare and Hogg, William},
	year = {2012},
	pages = {63--74},
}


@incollection{Becker2000multivariate,
  address = {San Diego, CA},
  author = {Becker, Betsy Jane},
  booktitle = {Handbook of Applied Multivariate Statistics and Mathematical Modeling},
  chapter = {17},
  doi = {10.1016/B978-012691360-6/50018-5},
  editor = {Brown, Steven D and Tinsley, Howard E.A.},
  pages = {499--525},
  publisher = {Academic Press},
  title = {{Multivariate Meta-analysis}},
  year = {2000}
}


@article{begg1994operating,
  title={Operating characteristics of a rank correlation test for publication bias},
  author={Begg, Colin B and Mazumdar, Madhuchhanda},
  journal={Biometrics},
  pages={1088--1101},
  year={1994},
  publisher={JSTOR}
}

@article{benjamin2018redefine,
  title={Redefine statistical significance},
  author={Benjamin, Daniel J and Berger, James O and Johannesson, Magnus and Nosek, Brian A and Wagenmakers, E-J and Berk, Richard and Bollen, Kenneth A and Brembs, Bj{\"o}rn and Brown, Lawrence and Camerer, Colin and others},
  journal={Nature human behaviour},
  volume={2},
  number={1},
  pages={6--10},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{bom2019kinked,
	title = {A kinked meta-regression model for publication bias correction},
	volume = {10},
	issn = {1759-2887},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1352},
	doi = {10.1002/jrsm.1352},
	language = {en},
	number = {4},
	urldate = {2022-06-12},
	journal = {Research Synthesis Methods},
	author = {Bom, Pedro R. D. and Rachinger, Heiko},
	year = {2019},
	pages = {497--514},
}

@article{boos1992generalized,
	title = {On Generalized Score Tests},
	volume = {46},
	issn = {00031305},
	url = {https://www.jstor.org/stable/2685328?origin=crossref},
	doi = {10.2307/2685328},
	language = {en},
	number = {4},
	urldate = {2019-05-29},
	journal = {The American Statistician},
	author = {Boos, Dennis D.},
	month = nov,
	year = {1992},
	pages = {327},
	file = {Boos (1992).pdf:/Users/mjoshi/Zotero/storage/RM8T4ML7/Boos (1992).pdf:application/pdf},
}

@article{boos2000montecarlo,
  title={Monte Carlo evaluation of resampling-based hypothesis tests},
  author={Boos, Dennis D. and Zhang, Ji},
  journal={Journal of the American Statistical Association},
  volume={95},
  number={450},
  pages={486--492},
  year={2000},
  publisher={Taylor \& Francis},
  doi = {10.1080/01621459.2000.10474226},
  
}

@article{boos2003introduction,
  title={Introduction to the bootstrap world},
  author={Boos, Dennis D},
  journal={Statistical science},
  volume={18},
  number={2},
  pages={168--174},
  year={2003},
  publisher={Institute of Mathematical Statistics}
}

@incollection{Borenstein2009effect,
  address = {New York, NY},
  author = {Borenstein, Michael},
  booktitle = {The Handbook of Research Synthesis and Meta-Analysis},
  editor = {Cooper, Harris M and Hedges, Larry V and Valentine, John C},
  pages = {221--236},
  publisher = {Russell Sage Foundation},
  title = {{Effect sizes for continuous data}},
  year = {2009}
}

@article{borenstein2019effect,
  title={Effect sizes for meta-analysis},
  author={Borenstein, MICHAEL and Hedges, LARRY V},
  journal={The handbook of research synthesis and meta-analysis},
  volume={3},
  pages={207--243},
  year={2019},
  publisher={Russell Sage Foundation West Sussex}
}


@misc{brunner2016how,
	title = {How replicable is psychology? {A} comparison of four methods of estimating replicability on the basis of test statistics in original studies},
	author = {Brunner, Jerry and Schimmack, Ulrich},
	year = {2016},
	file = {Brunner & Schimmack (2016):/Users/mjoshi/Zotero/storage/NUDDZI4X/Brunner & Schimmack (2016).pdf:application/pdf},
}

@article{brunner2018estimating,
	title = {Estimating Population Mean Power Under Conditions of Heterogeneity and Selection for Signiﬁcance},
	abstract = {In scientiﬁc ﬁelds that depend on signiﬁcance tests to document their ﬁndings, statistical power is a necessary condition for replicability. For any population of published results, there is a population of power values of the statistical tests on which conclusions are based. We give exact theoretical results showing how suppression of non-signiﬁcant results (publication bias) aﬀects the distribution of statistical power in a heterogeneous population of signiﬁcance tests. In a set of large-scale simulation studies, we compare four methods for estimating population mean power, based only on signiﬁcant results. The methods are maximum likelihood, extensions of of p-curve and p-uniform, and a new method we call z-curve. The versions of p-uniform and pcurve we consider perform well when eﬀect size is a single ﬁxed value, and under heterogeneity in sample size. When there is substantial variability in eﬀect size as well as sample size, both methods fail. If the assumptions of maximum likelihood are satisﬁed, it is the most accurate method of estimation under most conditions. When the assumptions of maximum likelihood are incorrect, z-curve is better. We describe and validate a conservative bootstrap conﬁdence interval that makes it possible to use z-curve with smaller samples of studies.},
	language = {en},
	author = {Brunner, Jerry and Schimmack, Ulrich},
	year = {2018},
	pages = {25},
	file = {Brunner & Schimmack (2018).pdf:/Users/mjoshi/Zotero/storage/RTLISDUL/Brunner & Schimmack (2018).pdf:application/pdf},
}

@article{cairo2020gray,
  title={Gray (literature) matters: Evidence of selective hypothesis reporting in social psychological research},
  author={Cairo, Athena H and Green, Jeffrey D and Forsyth, Donelson R and Behler, Anna Maria C and Raldiris, Tarah L},
  journal={Personality and Social Psychology Bulletin},
  volume={46},
  number={9},
  pages={1344--1362},
  year={2020},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{cameron2008bootstrap,
  title={Bootstrap-based improvements for inference with clustered errors},
  author={Cameron, A Colin and Gelbach, Jonah B and Miller, Douglas L},
  journal={The review of economics and statistics},
  volume={90},
  number={3},
  pages={414--427},
  year={2008},
  publisher={The MIT Press}
}

@article{carter2014publication,
  title = {Publication Bias and the Limited Strength Model of Self-Control: Has the Evidence for Ego Depletion Been Overestimated?},
  shorttitle = {Publication Bias and the Limited Strength Model of Self-Control},
  author = {Carter, Evan C. and McCullough, Michael E.},
  date = {2014-07-30},
  journaltitle = {Frontiers in Psychology},
  shortjournal = {Front. Psychol.},
  volume = {5},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2014.00823},
  url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2014.00823/abstract},
  urldate = {2025-03-05},
  langid = {english},
  file = {C:\Users\jamespustejovsky\Zotero\storage\YE58J5SX\Carter and McCullough - 2014 - Publication bias and the limited strength model of.pdf}
}

@article{carter2015series,
  title={A series of meta-analytic tests of the depletion effect: Self-control does not seem to rely on a limited resource.},
  author={Carter, Evan C and Kofler, Lilly M and Forster, Daniel E and McCullough, Michael E},
  journal={Journal of Experimental Psychology: General},
  volume={144},
  number={4},
  pages={796},
  year={2015},
  publisher={American Psychological Association}
}


@article{carter2019correcting,
  title={Correcting for bias in psychology: A comparison of meta-analytic methods},
  author={Carter, Evan C and Sch{\"o}nbrodt, Felix D and Gervais, Will M and Hilgard, Joseph},
  journal={Advances in Methods and Practices in Psychological Science},
  volume={2},
  number={2},
  pages={115--144},
  year={2019},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{chan2004empirical,
  title={Empirical evidence for selective reporting of outcomes in randomized trials: comparison of protocols to published articles},
  author={Chan, An-Wen and Hr{\'o}bjartsson, Asbj{\o}rn and Haahr, Mette T and G{\o}tzsche, Peter C and Altman, Douglas G},
  journal={Jama},
  volume={291},
  number={20},
  pages={2457--2465},
  year={2004},
  publisher={American Medical Association}
}

@misc{chen2024adapting,
  author = {Chen, Man and Pustejovsky, James E.},
  title = {Adapting methods for correcting selective reporting bias in meta-analysis of dependent effect sizes},
  date = {2024-10-23},
  url = {https://doi.org/10.31222/osf.io/jq52s},
  doi = {10.31222/osf.io/jq52s},
  langid = {en}
}

@article{chow2018published,
	title = {Do published studies yield larger effect sizes than unpublished studies in education and special education? {A} meta-review},
	volume = {30},
	issn = {1040-726X, 1573-336X},
	shorttitle = {Do {Published} {Studies} {Yield} {Larger} {Effect} {Sizes} than {Unpublished} {Studies} in {Education} and {Special} {Education}?},
	url = {http://link.springer.com/10.1007/s10648-018-9437-7},
	doi = {10.1007/s10648-018-9437-7},
	abstract = {Meta-analyses are used to make educational decisions in policy and practice. Publication bias refers to the extent to which published literature is more likely to have statistically significant results and larger sample sizes than studies that do not make it through the publication process. The purpose of the present study is to estimate the extent to which publication bias is present in a broad set of education and special education journals. We reviewed 222 meta-analyses to describe the prevalence of publication bias tests, and further identified 29 that met inclusion criteria for effect size extraction. Descriptive data reveal that 58\% of meta-analyses (n = 128) documented no effort to test for possible publication bias, and analyses of 72 difference statistics revealed that published studies were associated with significantly larger effect sizes than unpublished studies (d = 0.64). Exploratory moderator analyses revealed that effect size metric was a significant predictor of the difference between published and unpublished studies.},
	language = {en},
	number = {3},
	urldate = {2019-09-10},
	journal = {Educational Psychology Review},
	author = {Chow, Jason C. and Ekholm, Eric},
	month = sep,
	year = {2018},
	pages = {727--744},
	file = {Chow & Ekholm (2018).pdf:/Users/mjoshi/Zotero/storage/CH8BBAMR/Chow & Ekholm (2018).pdf:application/pdf},
}

@misc{CHTC,
  doi = {10.21231/GNT1-HW21},
  url = {https://chtc.cs.wisc.edu/},
  author = {{Center for High Throughput Computing}},
  title = {Center for High Throughput Computing},
  publisher = {Center for High Throughput Computing},
  year = {2006}
}

@article{citkowicz2017parsimonious,
  author = {Citkowicz, Martyna and Vevea, Jack L},
  doi = {10.1037/met0000119},
  journal = {Psychological Methods},
  number = {1},
  pages = {28--41},
  title = {{A parsimonious weight function for modeling publication bias}},
  volume = {22},
  year = {2017}
}

@article{Coburn2015publication,
  author = {Coburn, Kathleen M and Vevea, Jack L},
  doi = {10.1037/met0000046},
  journal = {Psychological Methods},
  number = {3},
  pages = {310--330},
  title = {{Publication bias as a function of study characteristics}},
  volume = {20},
  year = {2015}
}


@Manual{Coburn2017weightr,
  title = {weightr: Estimating Weight-Function Models for Publication Bias},
  author = {Kathleen M Coburn and Jack L Vevea},
  year = {2017},
  note = {R package version 1.1.2},
  url = {https://CRAN.R-project.org/package=weightr},
}
  


@article{copas1997inference,
	title = {Inference for non-random samples},
	volume = {59},
	doi = {10.1111/1467-9868.00055},
	number = {1},
	urldate = {2024-07-22},
	journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
	author = {Copas, John B. and Li, H. G.},
	year = {1997},
	pages = {55--95},
}



@article{copas1999what,
	title = {What Works?: {Selectivity} Models and Meta-Analysis},
	volume = {162},
	doi = {10.1111/1467-985X.00123},
	number = {1},
	journal = {Journal of the Royal Statistical Society Series A: Statistics in Society},
	author = {Copas, John B.},
	year = {1999},
	pages = {95--109},
}

@article{copas2000metaanalysis,
	title = {Meta-analysis, funnel plots and sensitivity analysis},
	volume = {1},
	issn = {1465-4644},
	doi = {10.1093/biostatistics/1.3.247},
	number = {3},
	journal = {Biostatistics},
	author = {Copas, John B. and Shi, Jian Qing},
	year = {2000},
	pages = {247--262},
}

@article{Copas2001sensitivity,
  author = {Copas, John B. and Shi, Jian Qing},
  journal = {Statistical Methods in Medical Research},
  pages = {251--265},
  title = {{A sensitivity analysis for publication bias in systematic reviews.}},
  volume = {10},
  year = {2001}
}



@article{copas2004bound,
	title = {A Bound for Publication Bias Based on the Fraction of Unpublished Studies},
	volume = {60},
	doi = {10.1111/j.0006-341X.2004.00161.x},
	number = {1},
	journal = {Biometrics},
	author = {Copas, John B. and Jackson, Dan},
	year = {2004},
	pages = {146--153},
}


@article{copas2013likelihood,
	title = {A likelihood-based Sensitivity analysis for publication bias in meta-analysis},
	volume = {62},
	doi = {10.1111/j.1467-9876.2012.01049.x},
	number = {1},
	journal = {Journal of the Royal Statistical Society Series C: Applied Statistics},
	author = {Copas, John B.},
	year = {2013},
	pages = {47--66},
}

@article{cox2004note,
  title = {A Note on Pseudolikelihood Constructed from Marginal Densities},
  author = {Cox, D. R. and Reid, N.},
  date = {2004-09-01},
  journaltitle = {Biometrika},
  shortjournal = {Biometrika},
  volume = {91},
  number = {3},
  pages = {729--737},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/91.3.729},
  url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/91.3.729},
  urldate = {2023-07-06},
  langid = {english},
  file = {C:\Users\jamespustejovsky\Zotero\storage\CLDFFQ8Y\Cox and Reid - 2004 - A note on pseudolikelihood constructed from margin.pdf}
}


@article{davidson2000bootstrap,
  title={Bootstrap tests: How many bootstraps?},
  author={Davidson, Russell and MacKinnon, James G},
  journal={Econometric Reviews},
  volume={19},
  number={1},
  pages={55--68},
  year={2000},
  publisher={Taylor \& Francis}
}

@book{davison1997bootstrap,
  title = {Bootstrap Methods and Their Applications},
  author = {Davison, A. C. and Hinkley, D. V.},
  date = {1997},
  publisher = {Cambridge University Press},
  location = {Cambridge}
}

@article{dear1992approach,
  author = {Dear, K B G and Begg, C B},
  journal = {Statistical Science},
  number = {2},
  pages = {237--245},
  title = {{An approach for assessing publication bias prior to performing a meta-analysis}},
  volume = {7},
  year = {1992}
}

@article{debray2018detecting,
	title = {Detecting small-study effects and funnel plot asymmetry in meta-analysis of survival data: a comparison of new and existing tests},
	doi = {10.1002/jrsm.1266},
	journaltitle = {Research Synthesis Methods},
	author = {Debray, Thomas P A  and Moons, Karel G M and Riley, Richard D},
	date = {2018}
}

@article{debruin2015cognitive,
	title = {Cognitive Advantage in Bilingualism: An Example of Publication Bias?},
	volume = {26},
	issn = {0956-7976},
	shorttitle = {Cognitive {Advantage} in {Bilingualism}},
	url = {https://doi.org/10.1177/0956797614557866},
	doi = {10.1177/0956797614557866},
	abstract = {It is a widely held belief that bilinguals have an advantage over monolinguals in executive-control tasks, but is this what all studies actually demonstrate? The idea of a bilingual advantage may result from a publication bias favoring studies with positive results over studies with null or negative effects. To test this hypothesis, we looked at conference abstracts from 1999 to 2012 on the topic of bilingualism and executive control. We then determined which of the studies they reported were subsequently published. Studies with results fully supporting the bilingual-advantage theory were most likely to be published, followed by studies with mixed results. Studies challenging the bilingual advantage were published the least. This discrepancy was not due to differences in sample size, tests used, or statistical power. A test for funnel-plot asymmetry provided further evidence for the existence of a publication bias.},
	language = {en},
	number = {1},
	urldate = {2019-06-03},
	journal = {Psychological Science},
	author = {de Bruin, Angela and Treccani, Barbara and Della Sala, Sergio},
	month = jan,
	year = {2015},
	pages = {99--107},
	file = {SAGE PDF Full Text:/Users/mjoshi/Zotero/storage/YC2AMK53/de Bruin et al. - 2015 - Cognitive Advantage in Bilingualism An Example of.pdf:application/pdf},
}


@misc{duan2020testing,
	title = {Testing for publication bias in meta-analysis under {Copas} selection model},
	doi = {10.48550/arXiv.2007.00836},
	author = {Duan, Rui and Piao, Jin and Marks-Anglin, Arielle and Tong, Jiayi and Lin, Lifeng and Chu, Haitao and Ning, Jing and Chen, Yong},
	year = {2020},
}

@article{du2017bayesian,
  title={A Bayesian “fill-in” method for correcting for publication bias in meta-analysis},
  author={Du, Han and Liu, Fang and Wang, Lijuan},
  journal={Psychological Methods},
  volume={22},
  number={4},
  pages={799},
  year={2017},
  publisher={American Psychological Association}
}

@article{duval2000nonparametric,
  title={A nonparametric “trim and fill” method of accounting for publication bias in meta-analysis},
  author={Duval, Sue and Tweedie, Richard},
  journal={Journal of the american statistical association},
  volume={95},
  number={449},
  pages={89--98},
  year={2000},
  publisher={Taylor \& Francis}
}

@article{duval2000trim,
  title={Trim and fill: a simple funnel-plot--based method of testing and adjusting for publication bias in meta-analysis},
  author={Duval, Sue and Tweedie, Richard},
  journal={Biometrics},
  volume={56},
  number={2},
  pages={455--463},
  year={2000},
  publisher={Oxford University Press}
}

@article{efron1987better,
  title = {Better Bootstrap Confidence Intervals},
  author = {Efron, Bradley},
  date = {1987-03-01},
  journaltitle = {Journal of the American Statistical Association},
  volume = {82},
  number = {397},
  pages = {171--185},
  issn = {0162-1459},
  doi = {10.1080/01621459.1987.10478410},
}

@article{egger1997bias,
	title = {Bias in meta-analysis detected by a simple, graphical test},
	volume = {315},
	pages = {629--634},
	number = {7109},
	journaltitle = {BMJ},
	author = {Egger, Matthias and Smith, George Davey and Schneider, Martin and Minder, Christoph},
	date = {1997}
}

@article{franco2016underreporting,
  title = {Underreporting in Psychology Experiments: Evidence From a Study Registry},
  shorttitle = {Underreporting in Psychology Experiments},
  author = {Franco, Annie and Malhotra, Neil and Simonovits, Gabor},
  date = {2016-01},
  journaltitle = {Social Psychological and Personality Science},
  volume = {7},
  number = {1},
  pages = {8--12},
  doi = {10.1177/1948550615598377},
  abstract = {Many scholars have raised concerns about the credibility of empirical findings in psychology, arguing that the proportion of false positives reported in the published literature dramatically exceeds the rate implied by standard significance levels. A major contributor of false positives is the practice of reporting a subset of the potentially relevant statistical analyses pertaining to a research project. This study is the first to provide direct evidence of selective underreporting in psychology experiments. To overcome the problem that the complete experimental design and full set of measured variables are not accessible for most published research, we identify a population of published psychology experiments from a competitive grant program for which questionnaires and data are made publicly available because of an institutional rule. We find that about 40\% of studies fail to fully report all experimental conditions and about 70\% of studies do not report all outcome variables included in the questionnaire. Reported effect sizes are about twice as large as unreported effect sizes and are about 3 times more likely to be statistically significant.},
  langid = {english}
}


@article{ferguson2012publication,
	title = {Publication bias in psychological science: {Prevalence}, methods for identifying and controlling, and implications for the use of meta-analyses.},
	volume = {17},
	issn = {1939-1463, 1082-989X},
	shorttitle = {Publication bias in psychological science},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0024445},
	doi = {10.1037/a0024445},
	language = {en},
	number = {1},
	urldate = {2020-03-10},
	journal = {Psychological Methods},
	author = {Ferguson, Christopher J. and Brannick, Michael T.},
	year = {2012},
	pages = {120--128},
	file = {download.pdf:/Users/mjoshi/Zotero/storage/SLVBGWBT/download.pdf:application/pdf},
}


@article{fernandezcastilla2019detecting,
	title = {Detecting selection bias in meta-analyses with multiple outcomes: A simulation study},
	url = {https://www.tandfonline.com/doi/full/10.1080/00220973.2019.1582470},
	doi = {10.1080/00220973.2019.1582470},
	abstract = {This study explores the performance of classical methods for detecting publication bias—namely, Egger’s regression test, Funnel Plot test, Begg’s Rank Correlation and Trim and Fill method—in meta-analysis of studies that report multiple effects. Publication bias, outcome reporting bias, and a combination of these were generated. Egger’s regression test and the Funnel Plot test were extended to three-level models, and possible cutoffs for the estimator of the Trim and Fill method were explored. Furthermore, we checked whether the combination of results of several methods yielded a better control of Type I error rates. Results show that no method works well across all conditions and that performance depends mainly on the population effect size value and the total variance.},
	language = {en},
	urldate = {2019-08-14},
	journal = {The Journal of Experimental Education},
	author = {Fernández-Castilla, Belén and Declercq, Lies and Jamshidi, Laleh and Beretvas, S. Natasha and Onghena, Patrick and Van den Noortgate, Wim},
	month = apr,
	year = {2019},
	pages = {1--20},
	file = {Fernández-Castilla et al. - 2019 - Detecting Selection Bias in Meta-Analyses with Mul.pdf:/Users/mjoshi/Zotero/storage/9WIBUDGS/Fernández-Castilla et al. - 2019 - Detecting Selection Bias in Meta-Analyses with Mul.pdf:application/pdf},
}

@article{flint2015there,
  title={Is there an excess of significant findings in published studies of psychotherapy for depression?},
  author={Flint, J and Cuijpers, P and Horder, J and Koole, SL and Munaf{\`o}, MR},
  journal={Psychological medicine},
  volume={45},
  number={2},
  pages={439--446},
  year={2015},
  publisher={Cambridge University Press}
}

@article{francis2013replication,
	title = {Replication, statistical consistency, and publication bias},
	volume = {57},
	issn = {00222496},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S002224961300014X},
	doi = {10.1016/j.jmp.2013.02.003},
	abstract = {Scientific methods of investigation offer systematic ways to gather information about the world; and in the field of psychology application of such methods should lead to a better understanding of human behavior. Instead, recent reports in psychological science have used apparently scientific methods to report strong evidence for unbelievable claims such as precognition. To try to resolve the apparent conflict between unbelievable claims and the scientific method many researchers turn to empirical replication to reveal the truth. Such an approach relies on the belief that true phenomena can be successfully demonstrated in well-designed experiments, and the ability to reliably reproduce an experimental outcome is widely considered the gold standard of scientific investigations. Unfortunately, this view is incorrect; and misunderstandings about replication contribute to the conflicts in psychological science. Because experimental effects in psychology are measured by statistics, there should almost always be some variability in the reported outcomes. An absence of such variability actually indicates that experimental replications are invalid, perhaps because of a bias to suppress contrary findings or because the experiments were run improperly. Recent investigations have demonstrated how to identify evidence of such invalid experiment sets and noted its appearance for prominent findings in experimental psychology. The present manuscript explores those investigative methods by using computer simulations to demonstrate their properties and limitations. The methods are shown to be a check on the statistical consistency of a set of experiments by comparing the reported power of the experiments with the reported frequency of statistical significance. Overall, the methods are extremely conservative about reporting inconsistency when experiments are run properly and reported fully. The manuscript also considers how to improve scientific practice to avoid inconsistency, and discusses criticisms of the investigative method.},
	language = {en},
	number = {5},
	urldate = {2019-05-28},
	journal = {Journal of Mathematical Psychology},
	author = {Francis, Gregory},
	month = oct,
	year = {2013},
	pages = {153--169},
	file = {Francis (2013).pdf:/Users/mjoshi/Zotero/storage/J4GYGKM9/Francis (2013).pdf:application/pdf},
}

@article{greenwald1975prejudice,
  title={Consequences of prejudice against the null hypothesis},
  author={Greenwald, A G},
  journal={Psychological Bulletin},
  volume={82},
  number={1},
  pages={1--20},
  year={1975},
  doi = {10.1037/h0076157}
}


@article{hagger2010ego,
  title = {Ego Depletion and the Strength Model of Self-Control: {{A}} Meta-Analysis},
  author = {Hagger, Martin S. and Wood, Chantelle and Stiff, Chris and Chatzisarantis, Nikos L. D.},
  date = {2010},
  journaltitle = {Psychological Bulletin},
  volume = {136},
  number = {4},
  pages = {495--525},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/a0019486},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0019486},
  urldate = {2018-11-16},
  langid = {english}
}


@article{harbord2006modified,
  title={A modified test for small-study effects in meta-analyses of controlled trials with binary endpoints},
  author={Harbord, Roger M and Egger, Matthias and Sterne, Jonathan AC},
  journal={Statistics in medicine},
  volume={25},
  number={20},
  pages={3443--3457},
  year={2006},
  publisher={Wiley Online Library}
}

@article{hedges1984estimation,
  title={Estimation of effect size under nonrandom sampling: The effects of censoring studies yielding statistically insignificant mean differences},
  author={Hedges, Larry V},
  journal={Journal of Educational Statistics},
  volume={9},
  number={1},
  pages={61--85},
  year={1984},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}


@book{hedges1985statistical,
  address = {Orlando, FL},
  author = {Hedges, Larry V and Olkin, Ingram},
  publisher = {Academic Press},
  title = {{Statistical Methods for Meta-Analysis}},
  year = {1985}
}

@article{hedges1992modeling,
	title = {Modeling Publication Selection Effects in Meta-Analysis},
	volume = {7},
	pages = {246--255},
	number = {2},
	journaltitle = {Statistical Science},
	author = {Hedges, Larry V},
	date = {1992}
}

@article{Hedges1996estimating,
  author = {Hedges, Larry V and Vevea, Jack L},
  doi = {10.3102/10769986021004299},
  journal = {Journal of Educational and Behavioral Statistics},
  number = {4},
  pages = {299},
  title = {{Estimating effect size under publication bias: Small sample properties and robustness of a random effects selection model}},
  volume = {21},
  year = {1996}
}

@incollection{hedges2005selection,
  title = {Selection method approaches},
  booktitle = {Publication Bias in Meta-Analysis},
  author = {Hedges, Larry V and Vevea, Jack},
  editor = {Rothstein, Hannah R. and Sutton, Alexander J. and Borenstein, Michael},
  year = {2005},
  pages = {145--174},
  publisher = {{John Wiley \& Sons, Ltd}},
  address = {{Chichester, UK}},
  doi = {10.1002/0470870168.ch9},
}


@article{Hedges2010robust,
  author = {Hedges, Larry V and Tipton, Elizabeth and Johnson, Matthew C},
  doi = {10.1002/jrsm.5},
  journal = {Research Synthesis Methods},
  number = {1},
  pages = {39--65},
  title = {{Robust variance estimation in meta-regression with dependent effect size estimates}},
  volume = {1},
  year = {2010}
}

@article{hedges2017plausibility,
	title = {Plausibility and influence in selection models: {A} comment on {Citkowicz} and {Vevea} (2017).},
	volume = {22},
	issn = {1939-1463, 1082-989X},
	shorttitle = {Plausibility and influence in selection models},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000108},
	doi = {10.1037/met0000108},
	language = {en},
	number = {1},
	urldate = {2019-05-28},
	journal = {Psychological Methods},
	author = {Hedges, Larry V},
	year = {2017},
	pages = {42--46},
	file = {Hedges (2017).pdf:/Users/mjoshi/Zotero/storage/WCMJJDU9/Hedges (2017).pdf:application/pdf},
}


@article{henmi2010confidence,
  title={Confidence intervals for random effects meta-analysis and robustness to publication bias},
  author={Henmi, Masayuki and Copas, John B},
  journal={Statistics in medicine},
  volume={29},
  number={29},
  pages={2969--2983},
  year={2010},
  publisher={Wiley Online Library}
}


@article{huang2021using,
	title = {Using clinical trial registries to inform {Copas} selection model for publication bias in meta-analysis},
	volume = {12},
	doi = {10.1002/jrsm.1506},
	number = {5},
	journal = {Research Synthesis Methods},
	author = {Huang, Ao and Komukai, Sho and Friede, Tim and Hattori, Satoshi},
	year = {2021},
	pages = {658--673},
}

@article{ioannidis2007appropriateness,
	title = {The appropriateness of asymmetry tests for publication bias in meta-analyses: a large survey},
	volume = {176},
	issn = {0820-3946, 1488-2329},
	shorttitle = {The appropriateness of asymmetry tests for publication bias in meta-analyses},
	url = {http://www.cmaj.ca/cgi/doi/10.1503/cmaj.060410},
	doi = {10.1503/cmaj.060410},
	abstract = {Background: Statistical tests for funnel-plot asymmetry are common in meta-analyses. Inappropriate application can generate misleading inferences about publication bias. We aimed to measure, in a survey of meta-analyses, how frequently the application of these tests would be not meaningful or inappropriate.},
	language = {en},
	number = {8},
	urldate = {2019-05-28},
	journal = {Canadian Medical Association Journal},
	author = {Ioannidis, J. P.A. and Trikalinos, T. A.},
	month = apr,
	year = {2007},
	pages = {1091--1096},
	file = {Ioannidis & Trikalinos (2007) asymmetry tests for publication bias.pdf:/Users/mjoshi/Zotero/storage/6PTZP8IQ/Ioannidis & Trikalinos (2007) asymmetry tests for publication bias.pdf:application/pdf},
}

@article{ioannidis2007authors,
	title = {Authors' response to {V} {Johnson} and {Y} {Yuan}},
	volume = {4},
	issn = {1740-7745, 1740-7753},
	url = {http://journals.sagepub.com/doi/10.1177/1740774507079433},
	doi = {10.1177/1740774507079433},
	language = {en},
	number = {3},
	urldate = {2019-05-28},
	journal = {Clinical Trials: Journal of the Society for Clinical Trials},
	author = {Ioannidis, John PA and Trikalinos, Thomas A},
	month = jun,
	year = {2007},
	pages = {256--257},
	file = {Ioannidis & Trikalinos (2007) response.pdf:/Users/mjoshi/Zotero/storage/PA5LSAFM/Ioannidis & Trikalinos (2007) response.pdf:application/pdf},
}

@article{ioannidis2007exploratory,
	title = {An exploratory test for an excess of significant findings},
	volume = {4},
	doi = {10.1177/1740774507079441},
	pages = {245--253},
	number = {3},
	journaltitle = {Clinical Trials},
	author = {Ioannidis, John P A and Trikalinos, Thomas A},
	date = {2007-06-01}
}

@article{ioannidis2013clarifications,
	title = {Clarifications on the application and interpretation of the test for excess significance and its extensions},
	volume = {57},
	issn = {00222496},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249613000278},
	doi = {10.1016/j.jmp.2013.03.002},
	abstract = {This commentary discusses challenges in the application of the test for excess significance (Ioannidis \& Trikalinos, 2007) including the definition of the body of evidence, the plausible effect size for power calculations and the threshold of statistical significance. Interpretation should be cautious, given that it is not possible to separate different mechanisms of bias (classic publication bias, selective analysis, and fabrication) that lead to an excess of significance and in some fields significance-related biases may follow a complex pattern (e.g. Proteus phenomenon and occasional preference for ‘‘negative’’ results). Likelihood ratio estimates can be used to generate the post-test probability of bias, and correcting effect estimates for bias is possible in theory, but may not necessarily be reliable.},
	language = {en},
	number = {5},
	urldate = {2019-05-28},
	journal = {Journal of Mathematical Psychology},
	author = {Ioannidis, John P.A.},
	month = oct,
	year = {2013},
	pages = {184--187},
	file = {Ioannidis (2013).pdf:/Users/mjoshi/Zotero/storage/ZBHTNC4Y/Ioannidis (2013).pdf:application/pdf},
}

@article{iyengar1988selection,
	title = {Selection {Models} and the {File} {Drawer} {Problem}},
	volume = {3},
	issn = {0883-4237},
	url = {http://projecteuclid.org/euclid.ss/1177013012},
	doi = {10.1214/ss/1177013012},
	abstract = {Meta-analysis consists of quantitative methods for combining evidence from different studies about a particular issue. A frequent criticism of meta-analysis is that it may be based on a biased sample of all studies that were done. In this paper, we use selection models, or weighted distributions, to deal with one source of bias, namely, the failure to report studies that do not yield statistically significant results. We apply selection models to two approaches that have been suggested for correcting the bias. The fail-safe sample size approach calculates the minimum number of unpublished studies showing nonsignificant results that must have been carried out in order to overturn the conclusion reached from the published studies. The maximum likelihood approach uses a weighted distribution to model the selection bias in the generation of the data and estimates various parameters of interest. We suggest the use of families of weight functions to model plausible biasing mechanisms to study the sensitivity of inferences about effect sizes. By using an example, we show that the maximum likelihood approach has several advantages over the fail-safe sample size approach.},
	language = {en},
	number = {1},
	urldate = {2019-05-28},
	journal = {Statistical Science},
	author = {Iyengar, Satish and Greenhouse, Joel B.},
	month = feb,
	year = {1988},
	pages = {109--117},
	file = {Iyengar & Greenhouse (1988).pdf:/Users/mjoshi/Zotero/storage/53EGCNLT/Iyengar & Greenhouse (1988).pdf:application/pdf},
}

@article{jackson2005modelling,
	title = {Modelling reporting bias: the operative mortality rate for ruptured abdominal aortic aneurysm repair},
	volume = {168},
	issn = {1467-985X},
	shorttitle = {Modelling reporting bias},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-985X.2005.00375.x},
	doi = {10.1111/j.1467-985X.2005.00375.x},
	abstract = {Summary. It is perhaps underappreciated that ruptured abdominal aortic aneurysm is a significant cause of mortality in the UK. The only curative treatment is an emergency operation and quantifying the success of this presents many difficulties. In particular, there is empirical evidence of reporting bias, suggesting that studies failing to report operating theatre mortality may be those where death in theatre is more common. We suggest a procedure for correcting for this bias and re-examine a recent meta-analysis of the available data. This casts considerable doubt on some conclusions from naïve analyses that do not take into account the potential bias. Perhaps most importantly, our procedure indicates a modest improvement in operating theatre mortality over the last 50 years, which is a trend that is not evident from the usual naïve analyses.},
	language = {en},
	number = {4},
	urldate = {2019-09-30},
	journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
	author = {Jackson, Dan and Copas, John and Sutton, Alex J.},
	year = {2005},
	keywords = {Meta-analysis, Meta-regression, Non-ignorable selection, Reporting bias},
	pages = {737--752},
	file = {Snapshot:/Users/mjoshi/Zotero/storage/JC7QWZKK/j.1467-985X.2005.00375.html:text/html},
}


@article{john2012measuring,
  title={Measuring the prevalence of questionable research practices with incentives for truth telling},
  author={John, Leslie K and Loewenstein, George and Prelec, Drazen},
  journal={Psychological science},
  volume={23},
  number={5},
  pages={524--532},
  year={2012},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}


@article{johnson2007comments,
	title = {Comments on `{An} exploratory test for an excess of significant findings' by {JPA} loannidis and {TA} {Trikalinos}},
	volume = {4},
	issn = {1740-7745, 1740-7753},
	url = {http://journals.sagepub.com/doi/10.1177/1740774507079437},
	doi = {10.1177/1740774507079437},
	language = {en},
	number = {3},
	urldate = {2019-05-28},
	journal = {Clinical Trials: Journal of the Society for Clinical Trials},
	author = {Johnson, Valen and Yuan, Ying},
	month = jun,
	year = {2007},
	pages = {254--255},
	file = {Johnson & Yuan (2007).pdf:/Users/mjoshi/Zotero/storage/NCAMBCXI/Johnson & Yuan (2007).pdf:application/pdf},
}

@article{joshi2022cluster,
  author = {Joshi, Megha and Pustejovsky, James E. and Beretvas, S.
    Natasha},
  title = {Cluster Wild Bootstrapping to Handle Dependent Effect Sizes
    in Meta-Analysis with a Small Number of Studies},
  journal = {Research Synthesis Methods},
  volume = {13},
  number = {4},
  pages = {457-477},
  date = {2022-02-08},
  url = {https://doi.org/10.1002/jrsm.1554},
  doi = {10.1002/jrsm.1554},
  langid = {en}
}
@article{konstantopoulos2011fixed,
	title = {Fixed effects and variance components estimation in three-level meta-analysis: {Three}-level meta-analysis},
	volume = {2},
	issn = {17592879},
	shorttitle = {Fixed effects and variance components estimation in three-level meta-analysis},
	url = {http://doi.wiley.com/10.1002/jrsm.35},
	doi = {10.1002/jrsm.35},
	language = {en},
	number = {1},
	urldate = {2019-09-30},
	journal = {Research Synthesis Methods},
	author = {Konstantopoulos, Spyros},
	month = mar,
	year = {2011},
	pages = {61--76},
	file = {Konstantopoulos (2011) 3-level MA.pdf:/Users/mjoshi/Zotero/storage/U8DD23XN/Konstantopoulos (2011) 3-level MA.pdf:application/pdf},
}




@article{kossmeier2020PowerEnhanced,
  title = {Power-Enhanced Funnel Plots for Meta-Analysis},
  author = {Kossmeier, Michael and Tran, Ulrich S. and Voracek, Martin},
  date = {2020-03-31},
  journaltitle = {Zeitschrift für Psychologie},
  publisher = {{Hogrefe Publishing}},
  issn = {2151-2604},
  url = {https://econtent.hogrefe.com/doi/10.1027/2151-2604/a000392},
}

@article{kraft2020interpreting,
  title={Interpreting effect sizes of education interventions},
  author={Kraft, Matthew A},
  journal={Educational researcher},
  volume={49},
  number={4},
  pages={241--253},
  year={2020},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{lancee2017outcome,
  title={Outcome reporting bias in randomized-controlled trials investigating antipsychotic drugs},
  author={Lancee, M and Lemmens, CMC and Kahn, RS and Vinkers, CH and Luykx, JJ},
  journal={Translational psychiatry},
  volume={7},
  number={9},
  pages={e1232--e1232},
  year={2017},
  publisher={Nature Publishing Group}
}


@article{lehmann2018meta,
  title={Meta-analysis of the effect of red on perceived attractiveness},
  author={Lehmann, Gabrielle K and Elliot, Andrew J and Calin-Jageman, Robert J},
  journal={Evolutionary Psychology},
  volume={16},
  number={4},
  pages={1474704918802412},
  year={2018},
  doi={10.1177/1474704918802412},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{leijten2018parenting,
	title = {Parenting behaviors that shape child compliance: {A} multilevel meta-analysis},
	volume = {13},
	issn = {1932-6203},
	shorttitle = {Parenting behaviors that shape child compliance},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0204929},
	doi = {10.1371/journal.pone.0204929},
	abstract = {Background What are the parenting behaviors that shape child compliance? Most research on parent-child interactions relies on correlational research or evaluations of “package deal” interventions that manipulate many aspects of parenting at the same time. Neither approach allows for identifying the specific parenting behaviors that shape child compliance. To overcome this, we systematically reviewed and meta-analyzed available evidence on the effects of experimentally manipulated, discrete parenting behaviors—a niche in parent-child interaction research that contributes unique information on the specific parenting behaviors that shape child behavior. Methods We identified studies by systematically searching databases and through contacting experts. Nineteen studies (75 effect sizes) on four discrete parenting behaviors were included: praise, verbal reprimands, time-out, and ignore. In multilevel models, we tested for each parenting behavior whether it increased child compliance, including both observed and parent-reported measures of child compliance. Results Providing “time-out” for noncompliance robustly increased both observed and parent-reported child compliance (ds = 0.84–1.72; 95\% CI 0.30 to 2.54). The same holds for briefly ignoring the child after non-compliance (ds = 0.36–1.77; 95\% CI 0.04 to 2.90). When observed and parent-reported outcomes were combined, but not when they were examined separately, verbal reprimands also increased child compliance (d = 0.72; 95\% CI 0.26 to 1.19). Praise did not increase child compliance (ds = –0.27–1.19; 95\% CI –2.04 to 1.59). Conclusion Our findings suggest that of the discrete parenting behaviors that are experimentally studied in multiple trials, especially time-out and ignore, and to some extent verbal reprimands, shape child compliance.},
	language = {en},
	number = {10},
	urldate = {2019-09-10},
	journal = {PLOS ONE},
	author = {Leijten, Patty and Gardner, Frances and Melendez-Torres, G. J. and Knerr, Wendy and Overbeek, Geertjan},
	month = oct,
	year = {2018},
	keywords = {Behavior, Child health, Children, Database searching, Metaanalysis, Motivation, Parenting behavior, Verbal behavior},
	pages = {e0204929},
	file = {Full Text PDF:/Users/mjoshi/Zotero/storage/5M8ZY5RP/Leijten et al. - 2018 - Parenting behaviors that shape child compliance A.pdf:application/pdf;Snapshot:/Users/mjoshi/Zotero/storage/A9IX39EV/article.html:text/html},
}


@book{light1984Summing,
  title = {Summing {{Up}}},
  author = {Light, Richard J. and Pillemer, David B.},
  date = {1984-10-15},
  eprint = {qel3lAm4K6gC},
  eprinttype = {googlebooks},
  publisher = {{Harvard University Press}},
  abstract = {How can a scientist or policy analyst summarize and evaluate what is already known about a particular topic? This book offers practical guidance.The amount and diversity of information generated by academic and policy researchers in the contemporary world is staggering. How is an investigator to cope with the tens or even hundreds of studies on a particular problem? How can conflicting findings be reconciled? Richard Light and David Pillemer have developed both general guidelines and step-by-step procedures that can be used to synthesize existing data. They show how to apply quantitative methods, including the newest statistical procedures and simple graphical displays, to evaluate a mass of studies and combine separate data sets. At the same time, they insist on the value of qualitative information, of asking the right questions, and of considering the context in which research is conducted. The authors use exemplary reviews in education, psychology, health, and the policy sciences to illustrate their suggestions.Written in nontechnical language and addressed to the beginning researcher as well as to the practicing professional, Summing Up will set a new standard for valid research reviews and is likely to become a methodological classic.},
  isbn = {978-0-674-85431-4},
  langid = {english},
  pagetotal = {212},
  keywords = {Education / General,Social Science / Reference,Social Science / Research}
}

@incollection{lindsay1988composite,
  title = {Composite Likelihood Methods},
  booktitle = {Contemporary {{Mathematics}}},
  author = {Lindsay, Bruce G.},
  editor = {Prabhu, N. U.},
  date = {1988},
  volume = {80},
  pages = {221--239},
  publisher = {American Mathematical Society},
  location = {Providence, Rhode Island},
  doi = {10.1090/conm/080/999014},
  url = {http://www.ams.org/conm/080/},
  urldate = {2023-07-06},
  isbn = {978-0-8218-5087-9 978-0-8218-7668-8},
  langid = {english}
}

@article{macaskill2001comparison,
	title = {A comparison of methods to detect publication bias in meta-analysis},
	volume = {20},
	issn = {0277-6715},
	doi = {10.1002/sim.698},
	pages = {641--654},
	number = {4},
	journaltitle = {Statistics in Medicine},
	shortjournal = {Stat Med},
	author = {Macaskill, P and Walter, S D and Irwig, L},
	date = {2001-02-28},
	pmid = {11223905},
	keywords = {Humans, Publication bias, Computer Simulation, Linear Models, Meta-Analysis as Topic, Sample Size, Statistics as Topic}
}

@article{marksanglin2020historical,
  title = {A Historical Review of Publication Bias},
  author = {Marks‐Anglin, Arielle and Chen, Yong},
  date = {2020-11},
  journaltitle = {Research Synthesis Methods},
  shortjournal = {Res Syn Meth},
  volume = {11},
  number = {6},
  pages = {725--742},
  issn = {1759-2879, 1759-2887},
  doi = {10.1002/jrsm.1452},
  url = {https://doi.org/10.1002/jrsm.1452},
  urldate = {2022-03-03},
  langid = {english},
  file = {C:\Users\James\Zotero\storage\23RQ7TX5\Marks‐Anglin and Chen - 2020 - A historical review of publication bias.pdf}
}

@article{matthes2015questionable,
  title={Questionable research practices in experimental communication research: A systematic analysis from 1980 to 2013},
  author={Matthes, J{\"o}rg and Marquart, Franziska and Naderer, Brigitte and Arendt, Florian and Schmuck, Desir{\'e}e and Adam, Karoline},
  journal={Communication methods and measures},
  volume={9},
  number={4},
  pages={193--207},
  year={2015},
  publisher={Taylor \& Francis}
}

@article{mathur2020sensitivity,
	title = {Sensitivity analysis for publication bias in meta‐analyses},
	volume = {69},
	issn = {0035-9254, 1467-9876},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/rssc.12440},
	doi = {10.1111/rssc.12440},
	pages = {1091--1119},
	number = {5},
	journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
	shortjournal = {J. R. Stat. Soc. C},
	author = {Mathur, Maya B and {VanderWeele}, Tyler J},
	urldate = {2022-10-13},
	date = {2020-11},
}

@article{mathur2021estimating,
	title = {Estimating publication bias in meta‐analyses of peer‐reviewed studies: {A} meta‐meta‐analysis across disciplines and journal tiers},
	volume = {12},
	issn = {1759-2879, 1759-2887},
	shorttitle = {Estimating publication bias in {\textless}span style="font-variant},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1464},
	doi = {10.1002/jrsm.1464},
	number = {2},
	journal = {Research Synthesis Methods},
	author = {Mathur, Maya B. and VanderWeele, Tyler J.},
	year = {2021},
	pages = {176--191},
}

@article{mavridis2013fully,
	title = {A fully {Bayesian} application of the {Copas} selection model for publication bias extended to network meta-analysis},
	volume = {32},
	doi = {10.1002/sim.5494},
	number = {1},
	journal = {Statistics in Medicine},
	author = {Mavridis, Dimitris and Sutton, Alex and Cipriani, Andrea and Salanti, Georgia},
	year = {2013},
	pages = {51--66},
}

@article{mavridis2014selection,
	title = {A selection model for accounting for publication bias in a full network meta-analysis},
	volume = {33},
	issn = {02776715},
	url = {http://doi.wiley.com/10.1002/sim.6321},
	doi = {10.1002/sim.6321},
	language = {en},
	number = {30},
	urldate = {2019-05-28},
	journal = {Statistics in Medicine},
	author = {Mavridis, Dimitris and Welton, Nicky J. and Sutton, Alex and Salanti, Georgia},
	month = dec,
	year = {2014},
	pages = {5399--5412},
	file = {Mavridis_et_al-2014-Statistics_in_Medicine.pdf:/Users/mjoshi/Zotero/storage/7AV6MXPU/Mavridis_et_al-2014-Statistics_in_Medicine.pdf:application/pdf},
}



@article{mcshane2016adjusting,
	title = {Adjusting for Publication Bias in Meta-Analysis An Evaluation of Selection Methods and Some Cautionary Notes},
	volume = {11},
	url = {http://pps.sagepub.com/content/11/5/730.short},
	pages = {730--749},
	number = {5},
	journaltitle = {Perspectives on Psychological Science},
	author = {{McShane}, Blakeley B and Böckenholt, Ulf and Hansen, Karsten T},
	urldate = {2016-11-01},
	date = {2016}
}

@article{moreno2009assessment,
	title = {Assessment of regression-based methods to adjust for publication bias through a comprehensive simulation study},
	volume = {9},
	issn = {1471-2288},
	url = {http://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-9-2},
	doi = {10.1186/1471-2288-9-2},
	number = {1},
	journaltitle = {{BMC} Medical Research Methodology},
	author = {Moreno, Santiago G and Sutton, Alex J and Ades, Ae and Stanley, Tom D and Abrams, Keith R and Peters, J L and Cooper, Nicola J},
	urldate = {2016-10-21},
	date = {2009-12},
	langid = {english}
}

@article{moreno2012generalized,
  title={A generalized weighting regression-derived meta-analysis estimator robust to small-study effects and heterogeneity},
  author={Moreno, Santiago G and Sutton, Alex J and Thompson, John R and Ades, AE and Abrams, Keith R and Cooper, Nicola J},
  journal={Statistics in medicine},
  volume={31},
  number={14},
  pages={1407--1417},
  year={2012},
  publisher={Wiley Online Library}
}

@article{morey2013consistency,
	title = {The consistency test does not–and cannot–deliver what is advertised: {A} comment on {Francis} (2013)},
	volume = {57},
	issn = {00222496},
	shorttitle = {The consistency test does not–and cannot–deliver what is advertised},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249613000291},
	doi = {10.1016/j.jmp.2013.03.004},
	abstract = {The statistical consistency test of Ioannidis and Trikalinos (2007) has been used recently by Francis (2012a,c,d,e,2013,in press), to argue that specific sets of experiments show evidence of publication bias. I argue that the test is unnecessary because publication bias exists almost everywhere as property of the research process, not individual studies. Furthermore, for several reasons, the test does not support the claims made on its behalf. Instead of focusing on testing sets of experiments for publication bias, we should focus on changes to scientific culture to reduce the bias.},
	language = {en},
	number = {5},
	urldate = {2019-05-28},
	journal = {Journal of Mathematical Psychology},
	author = {Morey, Richard D.},
	month = oct,
	year = {2013},
	pages = {180--183},
	file = {Morey (2013).pdf:/Users/mjoshi/Zotero/storage/3ZHH8YE7/Morey (2013).pdf:application/pdf},
}

@article{mueller2016methods,
	title = {Methods for detecting, quantifying, and adjusting for dissemination bias in meta-analysis are described},
	volume = {80},
	issn = {08954356},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0895435616303018},
	doi = {10.1016/j.jclinepi.2016.04.015},
	abstract = {Objective: To systematically review methodological articles which focus on nonpublication of studies and to describe methods of detecting and/or quantifying and/or adjusting for dissemination in meta-analyses. To evaluate whether the methods have been applied to an empirical data set for which one can be reasonably conﬁdent that all studies conducted have been included. Study Design and Setting: We systematically searched Medline, the Cochrane Library, and Web of Science, for methodological articles that describe at least one method of detecting and/or quantifying and/or adjusting for dissemination bias in meta-analyses.
Results: The literature search retrieved 2,224 records, of which we ﬁnally included 150 full-text articles. A great variety of methods to detect, quantify, or adjust for dissemination bias were described. Methods included graphical methods mainly based on funnel plot approaches, statistical methods, such as regression tests, selection models, sensitivity analyses, and a great number of more recent statistical approaches. Only few methods have been validated in empirical evaluations using unpublished studies obtained from regulators (Food and Drug Administration, European Medicines Agency).
Conclusion: We present an overview of existing methods to detect, quantify, or adjust for dissemination bias. It remains difﬁcult to advise which method should be used as they are all limited and their validity has rarely been assessed. Therefore, a thorough literature search remains crucial in systematic reviews, and further steps to increase the availability of all research results need to be taken. Ó 2016 Elsevier Inc. All rights reserved.},
	language = {en},
	urldate = {2019-05-28},
	journal = {Journal of Clinical Epidemiology},
	author = {Mueller, Katharina Felicitas and Meerpohl, Joerg J. and Briel, Matthias and Antes, Gerd and von Elm, Erik and Lang, Britta and Motschall, Edith and Schwarzer, Guido and Bassler, Dirk},
	month = dec,
	year = {2016},
	pages = {25--33},
	file = {Mueller et al. (2019).pdf:/Users/mjoshi/Zotero/storage/23EFM7BM/Mueller et al. (2019).pdf:application/pdf},
}

@article{nakagawa2023quantitative,
  title = {Quantitative Evidence Synthesis: A Practical Guide on Meta-Analysis, Meta-Regression, and Publication Bias Tests for Environmental Sciences},
  shorttitle = {Quantitative Evidence Synthesis},
  author = {Nakagawa, Shinichi and Yang, Yefeng and Macartney, Erin L. and Spake, Rebecca and Lagisz, Malgorzata},
  date = {2023-04-24},
  journaltitle = {Environmental Evidence},
  shortjournal = {Environ Evid},
  volume = {12},
  number = {1},
  pages = {8},
  issn = {2047-2382},
  doi = {10.1186/s13750-023-00301-6},
  url = {https://doi.org/10.1186/s13750-023-00301-6},
  urldate = {2024-11-12},
  abstract = {Meta-analysis is a quantitative way of synthesizing results from multiple studies to obtain reliable evidence of an intervention or phenomenon. Indeed, an increasing number of meta-analyses are conducted in environmental sciences, and resulting meta-analytic evidence is often used in environmental policies and decision-making. We conducted a survey of recent meta-analyses in environmental sciences and found poor standards of current meta-analytic practice and reporting. For example, only\,\textasciitilde\,40\% of the 73 reviewed meta-analyses reported heterogeneity (variation among effect sizes beyond sampling error), and publication bias was assessed in fewer than half. Furthermore, although almost all the meta-analyses had multiple effect sizes originating from the same studies, non-independence among effect sizes was considered in only half of the meta-analyses. To improve the implementation of meta-analysis in environmental sciences, we here outline practical guidance for conducting a meta-analysis in environmental sciences. We describe the key concepts of effect size and meta-analysis and detail procedures for fitting multilevel meta-analysis and meta-regression models and performing associated publication bias tests. We demonstrate a clear need for environmental scientists to embrace multilevel meta-analytic models, which explicitly model dependence among effect sizes, rather than the commonly used random-effects models. Further, we discuss how reporting and visual presentations of meta-analytic results can be much improved by following reporting guidelines such as PRISMA-EcoEvo (Preferred Reporting Items for Systematic Reviews and Meta-Analyses for Ecology and Evolutionary Biology). This paper, along with the accompanying online tutorial, serves as a practical guide on conducting a complete set of meta-analytic procedures (i.e., meta-analysis, heterogeneity quantification, meta-regression, publication bias tests and sensitivity analysis) and also as a gateway to more advanced, yet appropriate, methods.},
  langid = {english},
  keywords = {Hierarchical models,Meta-analysis of variance,Missing data,Multivariate meta-analysis,Network meta-analysis,Robust variance estimation,Spatial dependency,Variance–covariance matrix},
  file = {C:\Users\jamespustejovsky\Zotero\storage\SUAFPYPX\Nakagawa et al. - 2023 - Quantitative evidence synthesis a practical guide.pdf}
}


@article{Nelson1986significance,
  title={Interpretation of significance levels and effect sizes by psychological researchers},
  author={Nelson, N and Rosenthal, R and Rosnow, R L},
  journal={American Psychologist},
  volume={41},
  number={11},
  pages={1299--1301},
  year={1986},
  doi = {10.1037/0003-066X.41.11.1299}
}



@article{newton1994approximate,
	title = {Approximate {Bayesian} inference with the weighted likelihood bootstrap},
	volume = {56},
	issn = {0035-9246},
	url = {https://doi.org/10.1111/j.2517-6161.1994.tb01956.x},
	doi = {10.1111/j.2517-6161.1994.tb01956.x},
	abstract = {We introduce the weighted likelihood bootstrap (WLB) as a way to simulate approximately from a posterior distribution. This method is often easy to implement, requiring only an algorithm for calculating the maximum likelihood estimator, such as iteratively reweighted least squares. In the generic weighting scheme, the WLB is first order correct under quite general conditions. Inaccuracies can be removed by using the WLB as a source of samples in the sampling-importance resampling (SIR) algorithm, which also allows incorporation of particular prior information. The SIR-adjusted WLB can be a competitive alternative to other integration methods in certain models. Asymptotic expansions elucidate the second-order properties of the WLB, which is a generalization of Rubin's Bayesian bootstrap. The calculation of approximate Bayes factors for model comparison is also considered. We note that, given a sample simulated from the posterior distribution, the required marginal likelihood may be simulation consistently estimated by the harmonic mean of the associated likelihood values; a modification of this estimator that avoids instability is also noted. These methods provide simple ways of calculating approximate Bayes factors and posterior model probabilities for a very wide class of models.},
	number = {1},
	urldate = {2024-10-17},
	journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
	author = {Newton, Michael A. and Raftery, Adrian E.},
	month = jan,
	year = {1994},
	pages = {3--26},
}


@article{ning2017maximum,
	title = {Maximum likelihood estimation and {EM} algorithm of {Copas}-like selection model for publication bias correction},
	volume = {18},
	doi = {10.1093/biostatistics/kxx004},
	number = {3},
	journal = {Biostatistics},
	author = {Ning, Jing and Chen, Yong and Piao, Jin},
	year = {2017},
	pages = {495--504},
}


@article{noble2020,
	title = {The Impact of Interactive Shared Book Reading on Children's Language Skills: A Randomized Controlled Trial.},
	volume = {6},
	doi = {https://doi.org/10.1044/2020_JSLHR-19-00288},
	number = {63},
	journal = {Educational Research Review},
	author = {Noble, Claire and Cameron-Faulkner, Thea and Jessop, Andrew and Coates, Anna and Sawyer, Hannah and Taylor-Ims, Rachel and Rowland, Caroline F},
	year = {2020},
	pages = {1878--1897},
}


@article{oBoyle2017chrysalis,
  title={The chrysalis effect: How ugly initial results metamorphosize into beautiful articles},
  author={O’Boyle Jr, Ernest Hugh and Banks, George Christopher and Gonzalez-Mul{\'e}, Erik},
  journal={Journal of Management},
  volume={43},
  number={2},
  pages={376--399},
  year={2017},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{peters2006comparison,
	title = {Comparison of two methods to detect publication bias in meta-analysis},
	volume = {295},
	pages = {676--680},
	number = {6},
	journaltitle = {Journal of the American Medical Association},
	author = {Peters, J L and Sutton, Alex J. and Jones, David R. and Abrams, Keith R. and Rushton, Lesley},
	date = {2006}
}


@article{pfeiffer2011quantifying,
	title = {Quantifying {Selective} {Reporting} and the {Proteus} {Phenomenon} for {Multiple} {Datasets} with {Similar} {Bias}},
	volume = {6},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0018362},
	doi = {10.1371/journal.pone.0018362},
	abstract = {Meta-analyses play an important role in synthesizing evidence from diverse studies and datasets that address similar questions. A major obstacle for meta-analyses arises from biases in reporting. In particular, it is speculated that findings which do not achieve formal statistical significance are less likely reported than statistically significant findings. Moreover, the patterns of bias can be complex and may also depend on the timing of the research results and their relationship with previously published work. In this paper, we present an approach that is specifically designed to analyze large-scale datasets on published results. Such datasets are currently emerging in diverse research fields, particularly in molecular medicine. We use our approach to investigate a dataset on Alzheimer’s disease (AD) that covers 1167 results from case-control studies on 102 genetic markers. We observe that initial studies on a genetic marker tend to be substantially more biased than subsequent replications. The chances for initial, statistically non-significant results to be published are estimated to be about 44\% (95\% CI, 32\% to 63\%) relative to statistically significant results, while statistically non-significant replications have almost the same chance to be published as statistically significant replications (84\%; 95\% CI, 66\% to 107\%). Early replications tend to be biased against initial findings, an observation previously termed Proteus phenomenon: The chances for nonsignificant studies going in the same direction as the initial result are estimated to be lower than the chances for nonsignificant studies opposing the initial result (73\%; 95\% CI, 55\% to 96\%). Such dynamic patters in bias are difficult to capture by conventional methods, where typically simple publication bias is assumed to operate. Our approach captures and corrects for complex dynamic patterns of bias, and thereby helps generating conclusions from published results that are more robust against the presence of different coexisting types of selective reporting.},
	language = {en},
	number = {3},
	urldate = {2019-05-28},
	journal = {PLoS ONE},
	author = {Pfeiffer, Thomas and Bertram, Lars and Ioannidis, John P. A.},
	editor = {Biondi-Zoccai, Giuseppe},
	month = mar,
	year = {2011},
	pages = {e18362},
	file = {Pfeiffer, Bertram, & Ioannidis (2011).PDF:/Users/mjoshi/Zotero/storage/9N832EBZ/Pfeiffer, Bertram, & Ioannidis (2011).PDF:application/pdf},
}


@article{piao2019copas,
	title = {Copas-like selection model to correct publication bias in systematic review of diagnostic test studies},
	volume = {28},
	issn = {0962-2802},
	url = {https://doi.org/10.1177/0962280218791602},
	doi = {10.1177/0962280218791602},
	number = {10-11},
	journal = {Statistical Methods in Medical Research},
	author = {Piao, Jin and Liu, Yulun and Chen, Yong and Ning, Jing},
	year = {2019},
	pages = {2912--2923},
}

@book{pigott2012advances,
  title={Advances in meta-analysis},
  author={Pigott, Terri},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{pigott2013outcome,
  title={Outcome-reporting bias in education research},
  author={Pigott, Therese D and Valentine, Jeffrey C and Polanin, Joshua R and Williams, Ryan T and Canada, Dericka D},
  journal={Educational Researcher},
  volume={42},
  number={8},
  pages={424--432},
  year={2013},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}


@article{polanin2016estimating,
  title={Estimating the difference between published and unpublished effect sizes: A meta-review},
  author={Polanin, Joshua R and Tanner-Smith, Emily E and Hennessy, Emily A},
  journal={Review of educational research},
  volume={86},
  number={1},
  pages={207--236},
  year={2016},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}


@article{preston2004adjusting,
  title = {Adjusting for Publication Bias: Modelling the Selection Process},
  shorttitle = {Adjusting for Publication Bias},
  author = {Preston, Carrol and Ashby, Deborah and Smyth, Rosalind},
  date = {2004-05},
  journaltitle = {Journal of Evaluation in Clinical Practice},
  shortjournal = {Evaluation Clinical Practice},
  volume = {10},
  number = {2},
  pages = {313--322},
  doi = {10.1111/j.1365-2753.2003.00457.x},
  langid = {english}
}

@article{pustejovsky2019testing,
  title={Testing for funnel plot asymmetry of standardized mean differences},
  author={Pustejovsky, James E and Rodgers, Melissa A},
  journal={Research Synthesis Methods},
  volume={10},
  number={1},
  pages={57--71},
  year={2019},
  publisher={Wiley Online Library}
}

@article{pustejovsky2022preventionscience,
  author = {Pustejovsky, James E. and Tipton, Elizabeth},
  title = {Meta-Analysis with Robust Variance Estimation: {Expanding}
    the Range of Working Models},
  journal = {Prevention Science},
  volume = {23},
  pages = {425-438},
  date = {2022-04-01},
  url = {https://doi.org/10.1007/s11121-021-01246-3},
  doi = {10.1016/j.jsp.2018.02.003},
  langid = {en}
}

@misc{pustejovsky2025estimation,
  author = {Pustejovsky, James E. and Citkowicz, Martyna and Joshi,
    Megha},
  title = {Estimation and Inference for Step-Function Selection Models
    in Meta-Analysis with Dependent Effects},
  date = {2025-05-28},
  url = {https://osf.io/preprints/metaarxiv/qg5x6_v1},
  doi = {10.31222/osf.io/qg5x6_v1},
  langid = {en}
}

@article{rao1948large,
	title = {Large sample tests of statistical hypotheses concerning several parameters with applications to problems of estimation},
	volume = {44},
	issn = {0305-0041, 1469-8064},
	url = {http://www.journals.cambridge.org/abstract_S0305004100023987},
	doi = {10.1017/S0305004100023987},
	language = {en},
	number = {01},
	urldate = {2019-05-29},
	journal = {Mathematical Proceedings of the Cambridge Philosophical Society},
	author = {Rao, C. Radhakrishna},
	month = jan,
	year = {1948},
	pages = {50},
}

@incollection{rao2005score,
	address = {Boston, MA},
	series = {Statistics for {Industry} and {Technology}},
	title = {Score {Test}: {Historical} {Review} and {Recent} {Developments}},
	isbn = {978-0-8176-4422-2},
	shorttitle = {Score {Test}},
	url = {https://doi.org/10.1007/0-8176-4422-9_1},
	abstract = {The three asymptotic tests, Neyman and Pearson Likelihood Ratio (LR), Wald’s statistic (W) and Rao’s score (RS)are referred to in statistical literature on testing of hypotheses as the Holy Trinity. All these tests are equivalent to the first-order of asymptotics, but differ to some extent in the second-order properties. Some of the merits and defects of these tests are presented.Some applications of the score test, recent developments on refining the score test and problems for further investigation are presented.},
	language = {en},
	urldate = {2019-05-31},
	booktitle = {Advances in {Ranking} and {Selection}, {Multiple} {Comparisons}, and {Reliability}: {Methodology} and {Applications}},
	publisher = {Birkhäuser Boston},
	author = {Rao, C. R.},
	editor = {Balakrishnan, N. and Nagaraja, H. N. and Kannan, N.},
	year = {2005},
	doi = {10.1007/0-8176-4422-9_1},
	keywords = {Composite hypothesis, Lagrangian multiplier (LM) test, Likelihood ratio (LR), Neyman-Rao test, Neyman’s C(α), Rao’s score (RS), Wald’s statistic (W)},
	pages = {3--20},
	file = {Springer Full Text PDF:/Users/mjoshi/Zotero/storage/3ES22WII/Rao - 2005 - Score Test Historical Review and Recent Developme.pdf:application/pdf},
}

@article{rao2013weighted,
  title = {A Weighted Composite Likelihood Approach to Inference for Two-Level Models from Survey Data},
  author = {Rao, J N K and Verret, François and Hidiroglou, Mike A},
  date = {2013},
  journaltitle = {Survey Methodology},
  volume = {39},
  number = {2},
  pages = {263--282},
  abstract = {Multi-level models are extensively used for analyzing survey data with the design hierarchy matching the model hierarchy. We propose a unified approach, based on a design-weighted log composite likelihood, for two-level models that leads to design-model consistent estimators of the model parameters even when the within cluster sample sizes are small provided the number of sample clusters is large. This method can handle both linear and generalized linear two-level models and it requires level 2 and level 1 inclusion probabilities and level 1 joint inclusion probabilities, where level 2 represents a cluster and level 1 an element within a cluster. Results of a simulation study demonstrating superior performance of the proposed method relative to existing methods under informative sampling are also reported.},
}


@article{rodgers2021evaluating,
  title={Evaluating meta-analytic methods to detect selective reporting in the presence of dependent effect sizes.},
  author={Rodgers, Melissa A and Pustejovsky, James E},
  journal={Psychological methods},
  volume={26},
  number={2},
  pages={141},
  year={2021},
  publisher={American Psychological Association}
}


@article{roest2015reporting,
  title={Reporting bias in clinical trials investigating the efficacy of second-generation antidepressants in the treatment of anxiety disorders: a report of 2 meta-analyses},
  author={Roest, Annelieke M and De Jonge, Peter and Williams, Craig D and De Vries, Ymkje Anna and Schoevers, Robert A and Turner, Erick H},
  journal={JAMA psychiatry},
  volume={72},
  number={5},
  pages={500--510},
  year={2015},
  publisher={American Medical Association}
}

@article{Rosenthal1963significance,
  title={The interpretation of levels of significance by psychological researchers},
  author={Rosenthal, R and Gaito, J},
  journal={The Journal of Psychology: Interdisciplinary and Applied},
  volume={55},
  number={1},
  pages={33--38},
  year={1963},
  doi = {10.1080/00223980.1963.9916596}
}

@article{Rosenthal1964significance,
  title={Further evidence for the cliff effect in the interpretation of levels of significance},
  author={Rosenthal, R and Gaito, J},
  journal={Psychological Reports},
  volume={15},
  number={2},
  pages={570},
  year={1964},
  doi = {10.2466/pr0.1964.15.2.570}
}




@incollection{Rothstein2005publication,
  title = {Publication Bias in Meta-Analysis},
  booktitle = {Publication {{Bias}} in {{Meta-Analysis}}: {{Prevention}}, {{Assessment}}, and {{Adjustments}}},
  author = {Rothstein, Hannah R and Sutton, Alexander J and Borenstein, Michael},
  editor = {Rothstein, Hannah R and Sutton, Alex J and Borenstein, Michael},
  date = {2005},
  pages = {1--7},
  publisher = {{John Wiley \& Sons}},
  location = {{West Sussex, England}},
  doi = {10.1002/0470870168},
  chapter = {1}
}

@article{rotnitzky1990hypothesis,
	title = {Hypothesis Testing of Regression Parameters in Semiparametric Generalized Linear Models for Cluster Correlated Data},
	volume = {77},
	issn = {00063444},
	url = {https://www.jstor.org/stable/2336986?origin=crossref},
	doi = {10.2307/2336986},
	abstract = {Generalized and 'working' Wald and score tests for regression coefficients in the class of semiparametric marginal generalized linear models for cluster correlated data (Liang \& Zeger, 1986) are proposed, and their asymptotic distribution examined. In addition, the asymptotic distribution of the naive likelihood ratio test, or deviance difference, is presented. Following Rao \& Scott (1984), we propose simple adjustments to such 'working' tests. The asymptotic distributions of the 'working' tests allow us to explore theoretical bounds on the ratios of the robust variance of the regression parameter estimators and their naive variance counterparts computed assuming independent observations. In addition, the adequacy of a particular choice of working correlation structure is considered. We illustrate our results with a numerical example.},
	language = {en},
	number = {3},
	urldate = {2019-07-05},
	journal = {Biometrika},
	author = {Rotnitzky, Andrea and Jewell, Nicholas P.},
	month = sep,
	year = {1990},
	pages = {485},
	file = {Rotnitzky, Jewell - 1990 - Hypothesis testing of regression parameters in semiparametric generalized linear models for cluster correlate.pdf:/Users/mjoshi/Zotero/storage/UKS8C2L3/Rotnitzky, Jewell - 1990 - Hypothesis testing of regression parameters in semiparametric generalized linear models for cluster correlate.pdf:application/pdf},
}


@article{rubin1981bayesian,
	title = {The {Bayesian} Bootstrap},
	volume = {9},
	issn = {0090-5364},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-9/issue-1/The-Bayesian-Bootstrap/10.1214/aos/1176345338.full},
	doi = {10.1214/aos/1176345338},
	language = {en},
	number = {1},
	urldate = {2022-10-24},
	journal = {The Annals of Statistics},
	author = {Rubin, Donald B.},
	year = {1981},
}

@article{Rufibach2011selection,
  author = {Rufibach, Kaspar},
  doi = {10.1002/bimj.201000240},
  journal = {Biometrical Journal},
  number = {4},
  pages = {689--704},
  title = {{Selection models with monotone weight functions in meta analysis}},
  volume = {53},
  year = {2011}
}

@article{schild2013less,
  title={Less is less: a systematic review of graph use in meta-analyses},
  author={Schild, Anne HE and Voracek, Martin},
  journal={Research synthesis methods},
  volume={4},
  number={3},
  pages={209--219},
  year={2013},
  publisher={Wiley Online Library}
}

@article{schimmack2012ironic,
	title = {The ironic effect of significant results on the credibility of multiple-study articles.},
	volume = {17},
	issn = {1939-1463, 1082-989X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0029487},
	doi = {10.1037/a0029487},
	abstract = {Cohen (1962) pointed out the importance of statistical power for psychology as a science, but statistical power of studies has not increased, while the number of studies in a single article has increased. It has been overlooked that multiple studies with modest power have a high probability of producing nonsignificant results because power decreases as a function of the number of statistical tests that are being conducted (Maxwell, 2004). The discrepancy between the expected number of significant results and the actual number of significant results in multiple-study articles undermines the credibility of the reported results, and it is likely that questionable research practices have contributed to the reporting of too many significant results (Sterling, 1959). The problem of low power in multiple-study articles is illustrated using Bem’s (2011) article on extrasensory perception and Gailliot et al.’s (2007) article on glucose and self-regulation. I conclude with several recommendations that can increase the credibility of scientific evidence in psychological journals. One major recommendation is to pay more attention to the power of studies to produce positive results without the help of questionable research practices and to request that authors justify sample sizes with a priori predictions of effect sizes. It is also important to publish replication studies with nonsignificant results if these studies have high power to replicate a published finding.},
	language = {en},
	number = {4},
	urldate = {2019-12-05},
	journal = {Psychological Methods},
	author = {Schimmack, Ulrich},
	year = {2012},
	pages = {551--566},
}

@article{simonsohn2014pcurve,
	title = {p-Curve and Effect Size: Correcting for Publication Bias Using Only Significant Results},
	volume = {9},
	doi = {10.1177/1745691614553988},
	pages = {666--681},
	number = {6},
	journaltitle = {Perspectives on Psychological Science},
	shortjournal = {Perspectives on Psychological Science},
	author = {Simonsohn, Uri and Nelson, Leif D and Simmons, Joseph P},
	date = {2014-11-01}
}

@article{stanley2008meta,
  title={Meta-regression methods for detecting and estimating empirical effects in the presence of publication selection},
  author={Stanley, Tom D},
  journal={Oxford Bulletin of Economics and statistics},
  volume={70},
  number={1},
  pages={103--127},
  year={2008},
  publisher={Wiley Online Library}
}

@article{stanley2014meta,
  title={Meta-regression approximations to reduce publication selection bias},
  author={Stanley, Tom D and Doucouliagos, Hristos},
  journal={Research Synthesis Methods},
  volume={5},
  number={1},
  pages={60--78},
  year={2014},
  publisher={Wiley Online Library}
}

@article{sterne2001funnel,
	title = {Funnel plots for detecting bias in meta-analysis: guidelines on choice of axis},
	volume = {54},
	shorttitle = {Funnel plots for detecting bias in meta-analysis},
	pages = {1046--1055},
	number = {10},
	journaltitle = {Journal of Clinical Epidemiology},
	author = {Sterne, Jonathan A C and Egger, Matthias},
	date = {2001}
}

@incollection{Sterne2005funnel,
  title = {The Funnel Plot},
  booktitle = {Publication {{Bias}} in {{Meta-Analysis}}: {{Prevention}}, {{Assessment}}, and {{Adjustments}}},
  author = {Sterne, Jonathan A. C. and Becker, Betsy Jane and Egger, Matthias},
  editor = {Rothstein, Hannah R and Sutton, Alex J and Borenstein, Michael},
  date = {2005},
  pages = {73--98},
  publisher = {{John Wiley \& Sons}},
  location = {{West Sussex, England}},
  doi = {10.1002/0470870168},
  chapter = {5}
}

@article{Sterne2011recommendations,
author = {Sterne, Jonathan A C and Sutton, Alexander J and Ioannidis, John P A and Terrin, Norma and Jones, David R and Lau, Joseph and Carpenter, James and R{\"{u}}cker, Gerta and Harbord, Roger M and Schmid, Christopher H and Tetzlaff, Jennifer and Deeks, Jonathan J and Peters, Jaime L and Macaskill, Petra and Schwarzer, Guido and Duval, Sue and Altman, Douglas G and Moher, David and Higgins, Julian P T},
doi = {10.1136/bmj.d4002},
journal = {BMJ},
pages = {d4002},
title = {{Recommendations for examining and interpreting funnel plot asymmetry in meta-analyses of randomised controlled trials.}},
volume = {343},
year = {2011}
}


@incollection{sutton2009publication,
	title = {Publication Bias},
	pages = {435--445},
	booktitle = {The Handbook of Research Synthesis and Meta-Analysis},
	publisher = {Russell Sage Foundation},
	author = {Sutton, {AJ}},
	date = {2009}
}

@article{Terrin2003heterogeneity,
  title={Adjusting for publication bias in the presence of heterogeneity},
  author={Terrin, N and Schmid, C H and Lau, J and Olkin, I},
  journal={Statistics in Medicine},
  volume={22},
  number={13},
  pages={2113--2126},
  year={2003},
  doi = {10.1002/sim.1461}
}

@article{thompson1999explaining,
  title={Explaining heterogeneity in meta-analysis: a comparison of methods},
  author={Thompson, Simon G and Sharp, Stephen J},
  journal={Statistics in medicine},
  volume={18},
  number={20},
  pages={2693--2708},
  year={1999},
  publisher={Wiley Online Library}
}

@article{tipton2015small,
  title={Small sample adjustments for robust variance estimation with meta-regression.},
  author={Tipton, Elizabeth},
  journal={Psychological methods},
  volume={20},
  number={3},
  pages={375},
  year={2015},
  publisher={American Psychological Association}
}

@article{tiptonpusto2015small,
  title={Small-sample adjustments for tests of moderators and model fit using robust variance estimation in meta-regression},
  author={Tipton, Elizabeth and Pustejovsky, James E},
  journal={Journal of Educational and Behavioral Statistics},
  volume={40},
  number={6},
  pages={604--634},
  year={2015},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{tipton2019current,
  title={Current practices in meta-regression in psychology, education, and medicine},
  author={Tipton, Elizabeth and Pustejovsky, James E and Ahmadi, Hedyeh},
  journal={Research synthesis methods},
  volume={10},
  number={2},
  pages={180--194},
  year={2019},
  publisher={Wiley Online Library}
}

@article{trinquart2014test,
	title = {A test for reporting bias in trial networks: simulation and case studies},
	volume = {14},
	issn = {1471-2288},
	shorttitle = {A test for reporting bias in trial networks},
	url = {https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-14-112},
	doi = {10.1186/1471-2288-14-112},
	abstract = {Background: Networks of trials assessing several treatment options available for the same condition are increasingly considered. Randomized trial evidence may be missing because of reporting bias. We propose a test for reporting bias in trial networks.
Methods: We test whether there is an excess of trials with statistically significant results across a network of trials. The observed number of trials with nominally statistically significant p-values across the network is compared with the expected number. The performance of the test (type I error rate and power) was assessed using simulation studies under different scenarios of selective reporting bias. Examples are provided for networks of antidepressant and antipsychotic trials, where reporting biases have been previously demonstrated by comparing published to Food and Drug Administration (FDA) data.
Results: In simulations, the test maintained the type I error rate and was moderately powerful after adjustment for type I error rate, except when the between-trial variance was substantial. In all, a positive test result increased moderately or markedly the probability of reporting bias being present, while a negative test result was not very informative. In the two examples, the test gave a signal for an excess of statistically significant results in the network of published data but not in the network of FDA data.
Conclusion: The test could be useful to document an excess of significant findings in trial networks, providing a signal for potential publication bias or other selective analysis and outcome reporting biases.},
	language = {en},
	number = {1},
	urldate = {2019-05-28},
	journal = {BMC Medical Research Methodology},
	author = {Trinquart, Ludovic and Ioannidis, John PA and Chatellier, Gilles and Ravaud, Philippe},
	month = dec,
	year = {2014},
	file = {Trinquart et al. (2014).pdf:/Users/mjoshi/Zotero/storage/C9FJED2S/Trinquart et al. (2014).pdf:application/pdf},
}


@article{vanaert2016conducting,
	title = {Conducting Meta-Analyses Based on \textit{p} Values: Reservations and Recommendations for Applying \textit{p} -Uniform and \textit{p} -Curve},
	volume = {11},
	issn = {1745-6916, 1745-6924},
	url = {http://journals.sagepub.com/doi/10.1177/1745691616650874},
	doi = {10.1177/1745691616650874},
	pages = {713--729},
	number = {5},
	journaltitle = {Perspectives on Psychological Science},
	author = {van Aert, Robbie C M and Wicherts, Jelte M and van Assen, Marcel A L M},
	urldate = {2019-05-28},
	date = {2016-09},
	langid = {english},
	file = {van Aert, Wicherts, & van Assen (2016).pdf:C\:\\Users\\jepus\\Zotero\\storage\\GALRMAX8\\van Aert, Wicherts, & van Assen (2016).pdf:application/pdf},
}

@article{vanaert2019publication,
	title = {Publication bias examined in meta-analyses from psychology and medicine: {A} meta-meta-analysis},
	volume = {14},
	issn = {1932-6203},
	shorttitle = {Publication bias examined in meta-analyses from psychology and medicine},
	url = {http://dx.plos.org/10.1371/journal.pone.0215052},
	doi = {10.1371/journal.pone.0215052},
	abstract = {Publication bias is a substantial problem for the credibility of research in general and of meta-analyses in particular, as it yields overestimated effects and may suggest the existence of non-existing effects. Although there is consensus that publication bias exists, how strongly it affects different scientific literatures is currently less well-known. We examined evidence of publication bias in a large-scale data set of primary studies that were included in 83 meta-analyses published in Psychological Bulletin (representing meta-analyses from psychology) and 499 systematic reviews from the Cochrane Database of Systematic Reviews (CDSR; representing meta-analyses from medicine). Publication bias was assessed on all homogeneous subsets (3.8\% of all subsets of meta-analyses published in Psychological Bulletin) of primary studies included in meta-analyses, because publication bias methods do not have good statistical properties if the true effect size is heterogeneous. Publication bias tests did not reveal evidence for bias in the homogeneous subsets. Overestimation was minimal but statistically significant, providing evidence of publication bias that appeared to be similar in both fields. However, a Monte-Carlo simulation study revealed that the creation of homogeneous subsets resulted in challenging conditions for publication bias methods since the number of effect sizes in a subset was rather small (median number of effect sizes equaled 6). Our findings are in line with, in its most extreme case, publication bias ranging from no bias until only 5\% statistically nonsignificant effect sizes being published. These and other findings, in combination with the small percentages of statistically significant primary effect sizes (28.9\% and 18.9\% for subsets published in Psychological Bulletin and CDSR), led to the conclusion that evidence for publication bias in the studied homogeneous subsets is weak, but suggestive of mild publication bias in both psychology and medicine.},
	language = {en},
	number = {4},
	urldate = {2019-05-28},
	journal = {PLOS ONE},
	author = {van Aert, Robbie C. M. and Wicherts, Jelte M. and van Assen, Marcel A. L. M.},
	editor = {Macleod, Malcolm R.},
	month = apr,
	year = {2019},
	pages = {e0215052},
	file = {van Aert et al. (2019).pdf:/Users/mjoshi/Zotero/storage/7NURHK2I/van Aert et al. (2019).pdf:application/pdf},
}

@article{vanaert2025Metaanalyzing,
  title = {Meta-Analyzing Nonpreregistered and Preregistered Studies.},
  author = {Van Aert, Robbie C. M.},
  date = {2025-02-17},
  journaltitle = {Psychological Methods},
  doi = {10.1037/met0000719},
}


@article{VanAssen2015meta,
  author = {van Assen, Marcel A L M and {Van Aert}, Robbie C M and Wicherts, J M},
  doi = {http://dx.doi.org/10.1037/met0000025},
  journal = {Psychological Methods},
  number = {3},
  pages = {293--309},
  title = {{Meta-analysis using effect size distributions of only statistically significant studies}},
  volume = {20},
  year = {2015}
}

@article{vandennoortgate2013threelevel,
  title = {Three-Level Meta-Analysis of Dependent Effect Sizes},
  author = {Van den Noortgate, Wim and López-López, José Antonio and Marín-Martínez, Fulgencio and Sánchez-Meca, Julio},
  date = {2013},
  journaltitle = {Behavior Research Methods},
  volume = {45},
  number = {2},
  pages = {576--594},
  doi = {10.3758/s13428-012-0261-6}
}

@article{vandennoortgate2015metaanalysis,
  title = {Meta-Analysis of Multiple Outcomes: A Multilevel Approach},
  author = {Van den Noortgate, Wim and López-López, José Antonio and Marín-Martínez, Fulgencio and Sánchez-Meca, Julio},
  date = {2015},
  journaltitle = {Behavior Research Methods},
  volume = {47},
  number = {4},
  pages = {1274--1294},
  doi = {10.3758/s13428-014-0527-2}
}


@article{varin2008composite,
  title = {On Composite Marginal Likelihoods},
  author = {Varin, Cristiano},
  date = {2008-02},
  journaltitle = {AStA Advances in Statistical Analysis},
  shortjournal = {AStA},
  volume = {92},
  number = {1},
  pages = {1--28},
  issn = {1863-8171, 1863-818X},
  doi = {10.1007/s10182-008-0060-7},
  url = {http://link.springer.com/10.1007/s10182-008-0060-7},
  urldate = {2023-07-06},
  langid = {english}
}

@article{varin2011overview,
  title = {An Overview of Composite Likelihood Methods},
  author = {Varin, Cristiano and Reid, Nancy and Firth, David},
  date = {2011},
  journaltitle = {Statistica Sinica},
  volume = {21},
  number = {1},
  eprint = {24309261},
  eprinttype = {jstor},
  pages = {5--42},
  publisher = {Institute of Statistical Science, Academia Sinica},
  issn = {1017-0405},
  url = {https://www.jstor.org/stable/24309261},
  urldate = {2023-08-14},
  abstract = {A survey of recent developments in the theory and application of composite likelihood is provided, building on the review paper of Varin (2008). A range of application areas, including geostatistics, spatial extremes, and space-time models, as well as clustered and longitudinal data and time series are considered. The important area of applications to statistical genetics is omitted, in light of Larribe and Fearnhead (2011). Emphasis is given to the development of the theory, and the current state of knowledge on efficiency and robustness of composite likelihood inference.}
}


@article{vevea1995general,
	title = {A general linear model for estimating effect size in the presence of publication bias},
	volume = {60},
	doi = {10.1007/BF02294384},
	pages = {419--435},
	number = {3},
	journaltitle = {Psychometrika},
	shortjournal = {Psychometrika},
	author = {Vevea, Jack L and Hedges, Larry V},
	date = {1995-09-01}
}

@article{vevea2005publication,
  title={Publication bias in research synthesis: sensitivity analysis using a priori weight functions.},
  author={Vevea, Jack L and Woods, Carol M},
  journal={Psychological methods},
  volume={10},
  number={4},
  pages={428},
  year={2005},
  publisher={American Psychological Association}
}

@article{Viechtbauer2010conducting,
  author = {Viechtbauer, Wolfgang},
  journal = {Journal of Statistical Software},
  keywords = {meta-analysis,meta-regression,mixed-effects model,moderator analysis,r},
  number = {3},
  pages = {1--48},
  title = {{Conducting meta-analyses in R with the metafor package}},
  volume = {36},
  year = {2010}
}

@article{viechtbauer2022locationscale,
	title = {Location‐scale models for meta‐analysis},
	issn = {1759-2879, 1759-2887},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1562},
	doi = {10.1002/jrsm.1562},
	language = {en},
	urldate = {2022-10-11},
	journal = {Research Synthesis Methods},
	author = {Viechtbauer, Wolfgang and López‐López, José Antonio},
	month = apr,
	year = {2022},
	pages = {jrsm.1562},
	file = {Full Text:/Users/mjoshi/Zotero/storage/V8UGNBDG/Viechtbauer and López‐López - 2022 - Location‐scale models for meta‐analysis.pdf:application/pdf},
}


@article{vevea2005publication,
	title = {Publication bias in research synthesis: Sensitivity analysis using a priori weight functions.},
	volume = {10},
	issn = {1939-1463, 1082-989X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/1082-989X.10.4.428},
	doi = {10.1037/1082-989X.10.4.428},
	shorttitle = {Publication Bias in Research Synthesis},
	pages = {428--443},
	number = {4},
	journaltitle = {Psychological Methods},
	author = {Vevea, Jack L and Woods, Carol M},
	date = {2005},
	langid = {english}
}

@article{williams2014consequences,
  title={Consequences of Outcome Reporting Bias in Education Research.},
  author={Williams, RT and Polanin, JR},
  journal={Society for Research on Educational Effectiveness},
  year={2014},
  publisher={ERIC}
}

@article{xu2020applications,
	title = {Applications of the Fractional-Random-Weight Bootstrap},
	volume = {74},
	issn = {0003-1305, 1537-2731},
	url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2020.1731599},
	doi = {10.1080/00031305.2020.1731599},
	pages = {345--358},
	number = {4},
	journaltitle = {The American Statistician},
	shortjournal = {The American Statistician},
	author = {Xu, Li and Gotwalt, Chris and Hong, Yili and King, Caleb B and Meeker, William Q},
	urldate = {2022-10-24},
	date = {2020-10-01},
}


@article{yang2023advanced,
  title = {Advanced Methods and Implementations for the Meta-Analyses of Animal Models: {{Current}} Practices and Future Recommendations},
  shorttitle = {Advanced Methods and Implementations for the Meta-Analyses of Animal Models},
  author = {Yang, Yefeng and Macleod, Malcolm and Pan, Jinming and Lagisz, Malgorzata and Nakagawa, Shinichi},
  date = {2023-03-01},
  journaltitle = {Neuroscience \& Biobehavioral Reviews},
  shortjournal = {Neuroscience \& Biobehavioral Reviews},
  volume = {146},
  pages = {105016},
  issn = {0149-7634},
  doi = {10.1016/j.neubiorev.2022.105016},
  url = {https://www.sciencedirect.com/science/article/pii/S014976342200505X},
  urldate = {2024-11-12},
  abstract = {Meta-analytic techniques have been widely used to synthesize data from animal models of human diseases and conditions, but these analyses often face two statistical challenges due to complex nature of animal data (e.g., multiple effect sizes and multiple species): statistical dependency and confounding heterogeneity. These challenges can lead to unreliable and less informative evidence, which hinders the translation of findings from animal to human studies. We present a literature survey of meta-analysis using animal models (animal meta-analysis), showing that these issues are not adequately addressed in current practice. To address these challenges, we propose a meta-analytic framework based on multilevel (linear mixed-effects) models. Through conceptualization, formulations, and worked examples, we illustrate how this framework can appropriately address these issues while allowing for testing new questions. Additionally, we introduce other advanced techniques such as multivariate models, robust variance estimation, and meta-analysis of emergent effect sizes, which can deliver robust inferences and novel biological insights. We also provide a tutorial with annotated R code to demonstrate the implementation of these techniques.},
  keywords = {Animal experiment,Animal research,Meta-regression,Multilevel meta-analysis,Multivariate meta-analysis,New effect size,PRISMA,Publication bias,Quantitative method,Research synthesis,Systematic review},
  file = {C:\Users\jamespustejovsky\Zotero\storage\NSZMWT6C\S014976342200505X.html}
}

@article{yi2016weighted,
  title = {A Weighted Composite Likelihood Approach for Analysis of Survey Data Under Two-Level Models},
  author = {Yi, Grace Y. and Rao, J. N. K. and Li, Haocheng},
  date = {2016},
  journaltitle = {Statistica Sinica},
  volume = {26},
  number = {2},
  eprint = {24721288},
  eprinttype = {jstor},
  pages = {569--587},
  publisher = {Institute of Statistical Science, Academia Sinica},
  url = {https://www.jstor.org/stable/24721288},
  doi = {10.5705/ss.2013.383}
}

@article{zheng2022How,
  title = {How Consistently Do 13 Clearinghouses Identify Social and Behavioral Development Programs as “{{Evidence-Based}}”?},
  author = {Zheng, Jingwen and Wadhwa, Mansi and Cook, Thomas D.},
  date = {2022-11},
  journaltitle = {Prevention Science},
  shortjournal = {Prev Sci},
  volume = {23},
  number = {8},
  pages = {1343--1358},
  issn = {1389-4986, 1573-6695},
  doi = {10.1007/s11121-022-01407-y},
  url = {https://doi.org/10.1007/s11121-022-01407-y},
  urldate = {2024-03-06},
  langid = {english}
}



@Manual{boot,
  title = {boot: Bootstrap R (S-Plus) Functions},
  author = {Angelo Canty and B. D. Ripley},
  year = {2021},
  note = {R package version 1.3-28},
}

@Manual{clubSandwich,
  title = {clubSandwich: Cluster-Robust (Sandwich) Variance Estimators with Small-Sample
Corrections},
  author = {James E. Pustejovsky},
  year = {2024},
  note = {R package version 0.5.11},
  url = {https://CRAN.R-project.org/package=clubSandwich},
}

@Manual{metadat,
    title = {metadat: Meta-Analysis Datasets},
    author = {Thomas White and Daniel Noble and Alistair Senior and W. Kyle Hamilton and Wolfgang Viechtbauer},
    year = {2022},
    note = {R package version 1.2-0},
    url = {https://CRAN.R-project.org/package=metadat},
  }

@Manual{nleqslv,
  title = {nleqslv: Solve Systems of Nonlinear Equations},
  author = {Berend Hasselman},
  year = {2023},
  note = {R package version 3.3.5},
  url = {https://CRAN.R-project.org/package=nleqslv},
}

@Article{optimx,
  title = {Unifying Optimization Algorithms to Aid Software System Users: {optimx} for {R}},
  author = {John C. Nash and Ravi Varadhan},
  journal = {Journal of Statistical Software},
  year = {2011},
  volume = {43},
  number = {9},
  pages = {1--14},
  doi = {10.18637/jss.v043.i09},
}
@Manual{parallel,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2022},
    url = {https://www.R-project.org/},
  }

@Manual{PublicationBias,
    title = {PublicationBias: Sensitivity Analysis for Publication Bias in Meta-Analyses},
    author = {Mika Braginsky and Maya Mathur and Tyler J. VanderWeele},
    year = {2023},
    note = {R package version 2.4.0},
    url = {https://CRAN.R-project.org/package=PublicationBias},
  }


@Manual{rcoreteam,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2023},
    url = {https://www.R-project.org/},
  }


@Manual{simhelpers,
  title = {simhelpers: Helper Functions for Simulation Studies},
  author = {Megha Joshi and James E. Pustejovsky},
  note = {R package version 0.3.1},
  year = {2024},
  url = {https://meghapsimatrix.github.io/simhelpers/},
}
@Article{tidyverse,
  title = {Welcome to the {tidyverse}},
  author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},
  year = {2019},
  journal = {Journal of Open Source Software},
  volume = {4},
  number = {43},
  pages = {1686},
  doi = {10.21105/joss.01686},
}
  
@Manual{weightr,
    title = {weightr: Estimating Weight-Function Models for Publication Bias},
    author = {Kathleen M. Coburn and Jack L. Vevea},
    year = {2019},
    note = {R package version 2.0.2},
    url = {https://CRAN.R-project.org/package=weightr},
  }


